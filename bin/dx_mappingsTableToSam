#!/usr/bin/env python

import dxpy
import math
from optparse import OptionParser
import re

#Usage: sample input: dx_MappingsTableToSamBwa --table_id <gtable_id> --output <filename>
#Example: dx_MappingsTableToSamBwa --table_id gtable-9yZvF200000PYKJyV4k00005 --output mappings.sam

def main():

    parser = OptionParser("Usage: % mappings_id file_name")
    parser.add_option("--table_id", dest="mappings_id", help="Mappings table id to read from")
    parser.add_option("--output", dest="file_name", help="Name of file to write SAM to")
    parser.add_option("--region_index_offset", dest="region_index_offset", type = "int", default = 0, help="Adjust regions by this amount. Useful for converting between zero and one indexed lists")
    parser.add_option("--region", "-L", "-l", dest="region", type="string",  action="append", help="Regions to extract mappings for, in the format ChrX:A-B")
    parser.add_option("--store_mappings_columns", dest="store_mappings_columns", action="store_true", default=False, help="Output mappings table columns not in the mandatory fields in the optional fields to allow for easy reimport of a modified SAM")
    parser.add_option("--output_ids", dest="output_ids", action="store_true", default=False, help="Write gtable ids as an optional field to allow for easy reimport")
    (opts, args) = parser.parse_args()

    
    mappingsTable = dxpy.open_dxgtable(opts.mappings_id)
    storeMappingsColumns = opts.store_mappings_columns
    writeIds = opts.output_ids
    
    
    try:
        originalContig = mappingsTable.get_details()['original_contigset']
    except:
        raise Exception("The original reference genome must be attached as a detail")
    
    contigDetails = dxpy.DXRecord(originalContig).get_details()['contigs']
    contigNames = contigDetails['names']
    contigSizes = contigDetails['sizes']
    
    outputFile = open(opts.file_name, 'w')
    
    for i in range(len(contigNames)):
        outputFile.write("@SQ\tSN:"+contigNames[i]+"\tLN:"+str(contigSizes[i])+"\n")

    col = {}
    names = mappingsTable.get_col_names()   
    for i in range(len(names)):
        col[names[i]] = i+1
    defaultCol = {"sequence":"", "name":"", "quality": "", "status": "UNMAPPED", "chr":"", "lo":0, "hi":0, "negative_strand":False, "error_probability":0, "qc":"", "cigar":"", "mate_id":-1, "status2":"UNMAPPED", "chr2":"", "lo2":0, "hi2":0, "negative_strand2":False, "proper_pair":False}

        
    if opts.region == None:  
        for row in mappingsTable.iterate_rows():
            writeRow(row, col, defaultCol, outputFile, storeMappingsColumns, writeIds)
    else:
        for region in opts.region:
            includeDictionary = {}
            intervalMatch = re.findall("(\w+):(\d+)-(\d+)", region)
            query = mappingsTable.genomic_range_query(intervalMatch[0][0],int(intervalMatch[0][1])+opts.region_index_offset,int(intervalMatch[0][2])+opts.region_index_offset,mode='overlap',index='gri')
            for row in mappingsTable.iterate_query_rows(query=query):
                writeRow(row, col, defaultCol, outputFile, storeMappingsColumns, writeIds)
        
        
        
        
    
def writeRow(row, col, defaultCol, outputFile, storeMappingsColumns, writeIds):
    
    values = {}
    for k,v in defaultCol.iteritems():
        if col.get(k) == None:
            values[k] = defaultCol[k]
        else:
            values[k] = row[col[k]]
    
    
    #This is something of a hack to deal with a bug in the import script.
    #   that bug is being fixed and when that change moves through the system
    #   this will be removed
    if values["chr2"] == "*" or values["chr2"] == '' and values["status2"] != "UNMAPPED":
        values["status2"] = "UNMAPPED"
    
    flag = 0x1*(values["mate_id"] >= -1 and values["mate_id"] <= 1) + 0x2*(values["proper_pair"] == True) + 0x4*(values["status"] == "UNMAPPED")
    flag += 0x8*(values["status2"] == "UNMAPPED") + 0x10*(values["negative_strand"] == True) + 0x20*(values["negative_strand2"] == True)
    flag += 0x40*(values["mate_id"] == 0) + 0x80*(values["mate_id"] == 1) + 0x100*(values["status"] == "SECONDARY")
    flag += 0x200*(values["qc"] == "not passing quality controls") + 0x400*(values["qc"] == "PCR or optical duplicate")
    flag += (0x200+0x400)*(values["qc"] == "both not qc and PCR or optical duplicate")
    
    chromosome = values["chr"]
    lo = values["lo"]+1
    if values["chr"] == "":
        chromosome = "*"
        lo = 0

    chromosome2 = values["chr2"]
    lo2 = values["lo2"]+1
    if values["chr2"] == "":
        chromosome2 = "*"
        lo2 = 0
        
    readName = values["name"]    
    if readName.strip("@") == "":
        readName = "*"
    orientation = 1
    
    if values["lo2"] != 0 and values["hi2"] == 0:
        print row

    if values["negative_strand"]:
        orientation = -1
    if values["mate_id"] == -1 or values["chr"] != values["chr2"] or values["chr"] == '' or values["chr"] == '*':
        tlen = 0
    else:
        tlen = str((max(int(values["hi2"]),int(values["hi"])) - min(int(values["lo2"]),int(values["lo"])))*(1-2*values["mate_id"]))

    if values.get("quality") == None:
        qual = "*"
    elif str(values["quality"][::orientation]) == "": 
        qual = "*"
    else:
        qual = str(values["quality"][::orientation])

    outputFile.write(readName.strip("@") + "\t" + str(flag) + "\t" + chromosome + "\t" + str(lo) + "\t")
    outputFile.write(str(values["error_probability"]) + "\t" + values["cigar"] + "\t" + chromosome2 + "\t")
    outputFile.write(str(lo2) + "\t" + str(tlen) + "\t" + values["sequence"][::orientation] + "\t")
    outputFile.write(qual))
    
    if storeMappingsColumns:
        tagHash = {"status": "Z0", "hi":"Z1", "negative_strand":"Z2", "qc":"Z3", "template_id":"Z4", "mate_id":"Z5", "status2":"Z6", "hi2":"Z7", "negative_strand2":"Z8", "proper_pair2":"Z9"}
        for k,v in tagHash.iteritems():
            if col.get(k) != None:
                outputFile.write("\t"+v+":"+"Z"+":"+str(values[k]))
    if writeIds:
        outputFile.write("\tZD:Z:"+str(row[0]))
    outputFile.write("\n")
    

main()