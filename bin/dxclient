#!/usr/bin/env python

import sys, os, datetime
import argparse

import dxpy
import json

def write_env_var(var, value):
    try:
        os.mkdir(os.path.expanduser('~/.dnanexus-env/'))
    except:
        pass
    with open(os.path.expanduser('~/.dnanexus-env/' + var), 'w') as fd:
        fd.write(value)

def load_env():
    try:
        for filename in os.listdir(os.path.expanduser('~/.dnanexus-env')):
            with open(os.path.expanduser('~/.dnanexus-env/'+filename), 'r') as fd:
                value = fd.read()
                # TODO: Find out how bad the line below is for Mac OS X.
                os.environ[filename] = value
    except:
        pass
    if 'DX_CLI_WD' not in os.environ:
        write_env_var("DX_CLI_WD", '/')
        os.environ['DX_CLI_WD'] = '/'

def get_json_from_stdin():
    user_json_str = raw_input('Type JSON here> ')
    return json.loads(user_json_str)

# Loading environment

load_env()

def login(args):
    # TODO: Remove this and replace with actual logic and interaction
    # when implemented
    write_env_var('DX_SECURITY_CONTEXT',
                  '{"auth_token":"outside","auth_token_type":"Bearer"}')
    write_env_var("DX_CLI_WD", '/')

def logout(args):
    write_env_var('DX_SECURITY_CONTEXT', '')

def set_host(args):
    write_env_var("DX_APISERVER_HOST", args.host)

def set_port(args):
    write_env_var("DX_APISERVER_PORT", args.port)

def set_project(args):
    write_env_var("DX_PROJECT_CONTEXT_ID", args.project)
    write_env_var("DX_CLI_WD", '/')

def set_wd(args):
    write_env_var("DX_CLI_WD", args.folder)

def pwd(args):
    print os.environ['DX_CLI_WD']

def api(args):
    json_input = json.loads(args.input_json)
    if args.input is not None:
        with open(args.input, 'r') as fd:
            data = fd.read()
            json_input = json.loads(data)
    elif args.stdin:
        json_input = get_json_from_stdin()
    print json.dumps(dxpy.DXHTTPRequest('/' + args.resource + '/' + args.method,
                                        json_input))

def clean_folder_path(path):
    folders = path.split('/')

    newpath = ""
    for folder in folders:
        if folder == '':
            continue
        newpath += '/' + folder
    if newpath == "":
        return '/'
    return newpath

def resolve_path(path):
    wd = os.environ['DX_CLI_WD']
    if path == '.':
        return wd
    elif path == '..':
        if wd == '/':
            return '/'
        else:
            return os.path.dirname(wd)
    elif path.startswith('/'):
        return clean_folder_path(path)
    else:
        return clean_folder_path(wd + '/' + path)

def cd(args):
    wd = os.environ['DX_CLI_WD']
    args.folder = resolve_path(args.folder)

    if not wd.startswith(args.folder):
        try:
            dxproj = dxpy.DXProject()
            dxproj.list_folder(folder=args.folder)
        except:
            print args.folder + ': No such file or directory found in project ' + os.environ['DX_PROJECT_CONTEXT_ID']
            return

    set_wd(args)

# TODO: add -l functionality
def ls(args):
    dxproj = dxpy.DXProject()
    args.folder = resolve_path(args.folder)

    resp = None
    try:
        resp = dxproj.list_folder(folder=args.folder, describe={})
    except dxpy.DXAPIError as detail:
        print detail
        return
    if args.json:
        print json.dumps(resp)
        return

    if not args.obj:
        for folder in resp["folders"]:
            if args.full:
                print folder
            else:
                print os.path.basename(folder) + '/'
    if not args.folders:
        for obj in resp["objects"]:
            if not args.all and obj['describe']['hidden']:
                continue
            if not args.name and not args.both:
                print obj['id']
            elif args.name and not args.both:
                print obj['describe']['name']
            else:
                print obj['id'] + '\t' + obj['describe']['name']

def mkdir(args):
    dxproj = dxpy.DXProject()
    args.folder = resolve_path(args.folder)
    try:
        dxproj.new_folder(folder=args.folder, parents=args.parents)
    except dxpy.DXAPIError as detail:
        print detail

def rmdir(args):
    dxproj = dxpy.DXProject()
    args.folder = resolve_path(args.folder)
    try:
        dxproj.remove_folder(folder=args.folder)
    except dxpy.DXAPIError as detail:
        print detail

def rm(args):
    dxproj = dxpy.DXProject()
    if args.all:
        folder = '/'
        if 'DX_CLI_WD' in os.environ:
            folder = os.environ['DX_CLI_WD']

        if not args.force:
            user_resp = raw_input('Confirm deleting all objects in folder \"' + folder + '\" (y/n): ')
            if user_resp != 'y':
                return
        def grab_id(ahash):
            return ahash['id']
        dxproj.remove_objects( map(grab_id, dxproj.list_folder(folder=folder)['objects']))
    else:
        dxproj.remove_objects(args.objects)

def mv(args):
    dxproj = dxpy.DXProject()
    objects = []
    folders = []
    for source in args.sources:
        try:
            dxpy.get_handler(source)
            objects.append(source)
        except:
            if not source.startswith('/'):
                source = '/' + source
            folders.append(source)
    if not args.destination.startswith('/'):
        args.destination = '/' + args.destination
    # Doesn't exactly make sense when we can't specify a source by name yet
    # try:
    #     dxproj.list_folder(args.destination)
    # except:
    #     if len(objects) != 1 or len(folders) != 0:
    #         raise SyntaxError()
    #     else:
    #         dxobj = dxpy.get_handler(objects[0])
    #         dxobj.rename(args.destination)

    try:
        dxproj.move(args.destination, objects=objects, folders=folders)
    except dxpy.DXAPIError as detail:
        print detail

def describe(args):
    desc = None
    if args.dxid.startswith('job'):
        try:
            desc = dxpy.DXJob(args.dxid).describe()
        except dxpy.DXAPIError as detail:
            print detail
            return

        if args.json:
            print json.dumps(desc)
        if not args.json:
            print "ID\t\t" + desc["id"]
            print "Class\t\t" + desc["class"]
            print "Project context\t" + desc["project"]
            print "Workspace\t" + desc["workspace"]
            print "Program\t\t" + desc["program"]
            print "State\t\t" + desc["state"]
            if desc["parentJob"] is None:
                print "Parent job\tNone"
            else:
                print "Parent job\t" + json.dumps(desc["parentJob"])
            print "Origin job\t" + desc["originJob"]
            print "Function\t" + desc["function"]
            print "Original Input\t" + json.dumps(desc["originalInput"])
            print "Input\t\t" + json.dumps(desc["input"])
            print "Output\t\t" + json.dumps(desc["output"])
            print "Launched by\t" + desc["launchedBy"]
            print "Created\t\t" + datetime.datetime.fromtimestamp(desc['created']/1000).ctime()
            print "Last modified\t" + datetime.datetime.fromtimestamp(desc['modified']/1000).ctime()
    elif args.dxid.startswith('project'):
        try:
            desc = dxpy.DXProject(args.dxid).describe() # TODO get args!
        except dxpy.DXAPIError as detail:
            print detail
            return

        if args.json:
            print json.dumps(desc)
        else: # TODO: Finish adding flags, etc.
            print "ID\t\t" + desc["id"]
            print "Class\t\t" + desc["class"]
            print "Name\t\t" + desc["name"]
            print "Description\t" + desc["description"]
            print "Protected\t" + json.dumps(desc["protected"])
            print "Restricted\t" + json.dumps(desc["restricted"])
            print "Created\t\t" + datetime.datetime.fromtimestamp(desc['created']/1000).ctime()
            print "Last modified\t" + datetime.datetime.fromtimestamp(desc['modified']/1000).ctime()            
    else:
        json_input = {}
        if args.project is not None:
            json_input["project"] = args.project
        else:
            json_input["project"] = os.environ["DX_PROJECT_CONTEXT_ID"]
        if args.properties:
            json_input["properties"] = True
        if args.details:
            json_input["details"] = True

        try:
            desc = dxpy.DXHTTPRequest('/' + args.dxid + '/describe', json_input)
        except dxpy.DXAPIError as detail:
            print detail
            return

        if args.json:
            print json.dumps(desc)
        else:
            # Must be a data object
            common_fields = ['id', 'class', 'project', 'folder', 'name', 'properties', 'tags', 'types',
                             'hidden', 'details', 'links', 'created', 'modified', 'state']
            print "ID\t\t" + desc["id"]
            print "Class\t\t" + desc["class"]
            print "Project\t\t" + desc["project"]
            print "Folder\t\t" + desc["folder"]
            print "Name\t\t" + desc["name"]
            print "State\t\t" + desc["state"]
            print "Hidden\t\t" + json.dumps(desc["hidden"])
            print "Types\t\t" + json.dumps(desc["types"])
            if 'properties' in desc:
                print "Properties\t" + json.dumps(desc["properties"])
            print "Tags\t\t" + json.dumps(desc["tags"])
            if 'details' in desc:
                print "Details\t\t" + json.dumps(desc["details"])
            print "Outgoing links\t" + json.dumps(desc["links"])
            print "Created\t\t" + datetime.datetime.fromtimestamp(desc['created']/1000).ctime()
            print "Last modified\t" + datetime.datetime.fromtimestamp(desc['modified']/1000).ctime()
            for field in desc:
                if field in common_fields:
                    continue
                else:
                    if field == "media":
                        print "Media type\t" + desc['media']
                    elif field == "size":
                        if desc["class"] == "file":
                            print "Size (bytes)\t" + str(desc['size'])
                        elif desc["class"] == "gtable":
                            print "Size (rows)\t" + str(desc['size'])
                        else:
                            print "Size\t\t" + str(desc['size'])
                    elif field == "columns":
                        coldescs = ""
                        for column in desc["columns"]:
                            coldescs += "\t\t" + column["name"] + " (" + column["type"] + ")\n"
                        print "Columns" + coldescs[:-1]
                    else: # Unhandled prettifying
                        print field + "\t\t" + json.dumps(desc[field])

def get_properties_from_args(args_properties):
    properties = None
    if args_properties is not None:
        if len(args_properties) % 2 != 0:
            raise SyntaxError('Even number of key/value strings expected for --properties')
        properties = {}
        for i in range(len(args_properties)/2):
            properties[ args_properties[2*i] ] = args_properties[2*i+1]
    return properties

def new_record(args):
    hidden = (args.visibility == 'hidden')
    properties = get_properties_from_args(args.properties)
    details = None
    if args.details is not None:
        try:
            details = json.loads(args.details)
        except:
            print 'Error: details could not be parsed as JSON'
    init_from = None
    if args.init is not None:
        init_from = dxpy.DXRecord(args.init)

    dxrecord = None
    try:
        dxrecord = dxpy.new_dxrecord(project=args.project, name=args.name,
                                     tags=args.tags, types=args.types, 
                                     hidden=hidden, properties=properties,
                                     details=details,
                                     folder=args.folder,
                                     parents=args.parents, init_from=init_from)
        print dxrecord.get_id()
    except dxpy.DXAPIError as detail:
        print detail

def new_gtable(args):
    hidden = (args.visibility == 'hidden')
    properties = get_properties_from_args(args.properties)
    details = None
    if args.details is not None:
        try:
            details = json.loads(args.details)
        except:
            print 'Error: details could not be parsed as JSON'

    json_input = {}
    if args.input is not None:
        with open(args.input, 'r') as fd:
            data = fd.read()
            json_input = json.loads(data)

    if 'columns' in json_input:
        args.columns = json_input['columns']
    elif args.columns is not None:
        args.columns = json.loads(args.columns)
    if 'indices' in json_input:
        args.indices = json_input['indices']
    elif args.indices is not None:
        args.indices = json.loads(args.indices)

    try:
        dxgtable = dxpy.new_dxgtable(project=args.project, name=args.name,
                                     tags=args.tags, types=args.types, 
                                     hidden=hidden, properties=properties,
                                     details=details,
                                     folder=args.folder,
                                     parents=args.parents,
                                     columns=args.columns,
                                     indices=args.indices)
        print dxgtable.get_id()
    except dxpy.DXAPIError as detail:
        print detail

def set_visibility(args):
    try:
        dxpy.DXHTTPRequest('/' + args.dxid + '/setVisibility',
                           {"hidden": (args.visibility == 'hidden')})
    except dxpy.DXAPIError as detail:
        print detail

def set_details(args):
    try:
        args.details = json.loads(args.details)
        dxpy.DXHTTPRequest('/' + args.dxid + '/setDetails',
                           args.details)
    except ValueError:
        print 'Error: details could not be parsed as JSON'
    except dxpy.DXAPIError as detail:
        print detail

def add_types(args):
    try:
        dxpy.DXHTTPRequest('/' + args.dxid + '/addTypes',
                           {"types": args.types})
    except dxpy.DXAPIError as detail:
        print detail

def remove_types(args):
    try:
        dxpy.DXHTTPRequest('/' + args.dxid + '/removeTypes',
                           {"types": args.types})
    except dxpy.DXAPIError as detail:
        print detail

def add_tags(args):
    try:
        dxpy.get_handler(args.dxid).add_tags(args.tags)
    except dxpy.DXAPIError as detail:
        print detail

def remove_tags(args):
    try:
        dxpy.get_handler(args.dxid).remove_tags(args.tags)
    except dxpy.DXAPIError as detail:
        print detail

def rename(args):
    try:
        dxpy.get_handler(args.dxid).rename(args.name)
    except dxpy.DXAPIError as detail:
        print detail

def set_properties(args):
    properties = get_properties_from_args(args.properties)
    try:
        dxpy.get_handler(args.dxid).set_properties(properties)
    except dxpy.DXAPIError as detail:
        print detail

def unset_properties(args):
    properties = {}
    for prop in args.properties:
        properties[prop] = None
    try:
        dxpy.get_handler(args.dxid).set_properties(properties)
    except dxpy.DXAPIError as detail:
        print detail

def file_get(args):
    filename = args.output
    if filename is None:
        try:
            filename = os.path.basename(dxpy.api.fileDescribe(args.dxid)['name'])
        except KeyError:
            filename = args.dxid
    try:
        dxpy.download_dxfile(args.dxid, filename)
    except dxpy.DXAPIError as detail:
        print detail

def file_put(args):
    print dxpy.upload_local_file(args.filename).get_id()

def gtable_get(args):
    gri_query = None
    if args.gri is not None:
        gri_query = dxpy.DXGTable.genomic_range_query(args.gri[0],
                                                      int(args.gri[1]),
                                                      int(args.gri[2]),
                                                      args.gri_mode,
                                                      args.gri_name)
    try:
        result = dxpy.DXGTable(args.dxid).get_rows(query=gri_query, starting=args.starting,
                                                   limit=args.limit)
        if args.json:
            print json.dumps(result)
            return
        if result["next"] is not None:
            print "Use as STARTING to continue query: " + str(result["next"])
        print "# retrieved rows: " + str(result["size"])
        for row in result["data"]:
            print json.dumps(row)
    except dxpy.DXAPIError as detail:
        print detail

def find_jobs(args):
    try:
        results = list(dxpy.find_jobs(launched_by=args.user, program=args.program, project=args.project,
                                      state=args.state, origin_job=args.origin, parent_job=args.parent,
                                      describe=args.nodesc,
                                      modified_after=args.mod_after, modified_before=args.mod_before))

        if args.json:
            print json.dumps(results)
            return
        if not args.nodesc:
            for result in results:
                print result["id"]
        else:
            job_ids = {}
            job_children = {}
            origin_jobs = []
            for i in range(len(results)):
                job_ids[results[i]['id']] = i
                parent = results[i]['describe']['parentJob']
                if parent is None:
                    origin_jobs.append(i)
                elif parent in job_children:
                    job_children[parent].append(i)
                else:
                    job_children[parent] = [i]

            def print_children(parent_id, num_tabs):
                print_string = ""
                for j in range(num_tabs):
                    print_string += '\t'
                print_string += parent_id + ' (' + results[ job_ids[parent_id] ]['describe']['state'] + ')'
                print print_string

                if parent_id in job_children:
                    for child in job_children[parent_id]:
                        print_children(results[child]['id'], num_tabs + 1)

            for origin_job in origin_jobs:
                orig_id = results[origin_job]["id"]
                print_children(orig_id, 0)
    except dxpy.DXAPIError as detail:
        print detail

def find_data(args):
    properties = get_properties_from_args(args.properties)
    try:
        results = list(dxpy.find_data_objects(classname=args.classname, state=args.state,
                                              visibility=args.visibility, properties=properties,
                                              name=args.name,
                                              type_=args.type, tag=args.tag, link=args.link,
                                              project=args.project, folder=args.folder,
                                              recurse=args.recurse,
                                              modified_after=args.mod_after, modified_before=args.mod_before,
                                              created_after=args.created_after, created_before=args.created_before,
                                              describe=args.describe))
        if args.json:
            print json.dumps(results)
            return
        for result in results:
            print result["id"]
    except dxpy.DXAPIError as detail:
        print detail

def close(args):
    try:
        obj = dxpy.get_handler(args.dxid)
        obj.close()
    except dxpy.DXAPIError as detail:
        print detail
    if args.block:
        obj._wait_on_close()

global_args = argparse.ArgumentParser(add_help=False)
global_args.add_argument('--json', help='Display return value in JSON', action='store_true')

parser = argparse.ArgumentParser(epilog='README: If you have not already set environment variables in your shell to specify the API server\'s host and port and/or your default project, use the \'set\' subcommand to set these values for the command-line client.  NOTE: Running \'dxclient login\' at the moment will set your variables for using the \'outside\' token.', description='DNAnexus Command-Line Client, API v1.0.0')

subparsers = parser.add_subparsers()

parser_set = subparsers.add_parser('set', help='Sets default values for communication with the API server',
                                   description='Sets default values for communication with the API server')
subparsers_set = parser_set.add_subparsers()

parser_set_host = subparsers_set.add_parser('host', help='Sets the API server hostname')
parser_set_host.add_argument('host', help='API server hostname')
parser_set_host.set_defaults(func=set_host)

parser_set_port = subparsers_set.add_parser('port', help='Sets the API server port number')
parser_set_port.add_argument('port', help='API server port number')
parser_set_port.set_defaults(func=set_port)

parser_set_project = subparsers_set.add_parser('project', help='Sets the default project ID')
parser_set_project.add_argument('project', help='Project ID')
parser_set_project.set_defaults(func=set_project)

parser_login = subparsers.add_parser('login', help='Log in and acquire credentials', description='Log in interactively and acquire credentials')
parser_login.set_defaults(func=login)

parser_logout = subparsers.add_parser('logout', help='Log out and remove credentials', description='Log out and remove credentials')
parser_logout.set_defaults(func=logout)

parser_ls = subparsers.add_parser('ls', help='List folders and objects in a folder',
                                  description='List folders and/or objects in a folder',
                                  parents=[global_args])
parser_ls.add_argument('-a', '--all', help='show hidden files', action='store_true')
parser_ls.add_argument('-l', help='use a long listing format', action='store_true')
parser_ls.add_argument('--name', help='show names instead of object IDs', action='store_true')
parser_ls.add_argument('--both', help='show both names and object IDs', action='store_true')
parser_ls.add_argument('--obj', help='show only objects', action='store_true')
parser_ls.add_argument('--folders', help='show only folders', action='store_true')
parser_ls.add_argument('--full', help='show full paths of folders', action='store_true')
parser_ls.add_argument('folder', help='folder to list, default is \"/\"', nargs='?', default='.')
parser_ls.set_defaults(func=ls)

parser_cd = subparsers.add_parser('cd', help='Change the current working directory',
                                  description='Change the current working directory')
parser_cd.add_argument('folder', help='Folder to which to change the current working directory, default is \"/\"', nargs='?', default='/')
parser_cd.set_defaults(func=cd)

parser_pwd = subparsers.add_parser('pwd', help='Print current working directory',
                                   description='Print current working directory')
parser_pwd.set_defaults(func=pwd)

parser_mkdir = subparsers.add_parser('mkdir', help='Create a new folder',
                                     description='Create a new folder')
parser_mkdir.add_argument('-p', '--parents', help='no error if existing, create parent directories as needed', action='store_true')
parser_mkdir.add_argument('folder', help='folder to create; full path is required')
parser_mkdir.set_defaults(func=mkdir)

parser_rmdir = subparsers.add_parser('rmdir', help='Remove a folder',
                                     description='Remove a folder')
parser_rmdir.add_argument('folder', help='folder to remove; full path is required')
parser_rmdir.set_defaults(func=rmdir)

parser_rm = subparsers.add_parser('rm', help='Remove objects',
                                  description='Remove objects')
parser_rm.add_argument('objects', help='object IDs to remove', nargs='*')
parser_rm.add_argument('--all', help='Remove all objects in the current working directory.', action='store_true')
parser_rm.add_argument('-f', '--force', help='Execute without asking for confirmations', action='store_true')
parser_rm.add_argument('-r', '--recursive', help='Recurse into a directory')
parser_rm.set_defaults(func=rm)

parser_mv = subparsers.add_parser('mv', help='Move a objects and/or folders',
                                  description='Move a objects and/or folders')
parser_mv.add_argument('sources', help='Object IDs and/or folder names to move', nargs='*')
parser_mv.add_argument('destination', help='Folder into which to move the sources')
parser_mv.set_defaults(func=mv)

parser_file = subparsers.add_parser('file', help='Interact with remote files')
subparsers_file = parser_file.add_subparsers()

parser_file_get = subparsers_file.add_parser('get', help='Download a file')
parser_file_get.add_argument('dxid', help='file ID to download')
parser_file_get.add_argument('-o', '--output', help='local filename to be saved; if not supplied, the remote file\'s name or ID will be used')
parser_file_get.set_defaults(func=file_get)

parser_file_put = subparsers_file.add_parser('put', help='Upload a file')
parser_file_put.add_argument('filename', help='local filename to upload')
parser_file_put.set_defaults(func=file_put)

parser_gtable = subparsers.add_parser('gtable', help='Interact with remote gtables')
subparsers_gtable = parser_gtable.add_subparsers()

parser_gtable_get = subparsers_gtable.add_parser('get', help='Retrieve rows from a gtable',
                                                 parents=[global_args])
parser_gtable_get.add_argument('--starting', type=int, help='Specify starting row ID (provided by \'next\' if continuing a previous query) for the given query')
parser_gtable_get.add_argument('--limit', type=int, help='Specify a limit to the number of rows returned')
parser_gtable_get.add_argument('--gri', nargs=3, metavar=('CHR', 'LO', 'HI'), help='Specify chromosome name, low coordinate, and high coordinate for Genomic Range Index')
parser_gtable_get.add_argument('--gri_mode', help='Specify the mode of the GRI query (\'overlap\' or \'enclose\'; default \'overlap\')', default="overlap")
parser_gtable_get.add_argument('--gri_name', help='Override the default name of the Genomic Range Index (default: "gri"))', default="gri")
parser_gtable_get.add_argument('dxid', help='GTable ID from which to fetch rows')
parser_gtable_get.set_defaults(func=gtable_get)

parser_describe = subparsers.add_parser('describe', help='Describe a remote object', description='Describe a remote object',
                                        parents=[global_args])
parser_describe.add_argument('--project', help='Specify hint for which project to access, default is default project')
parser_describe.add_argument('--properties', help='Include properties', action='store_true')
parser_describe.add_argument('--details', help='Include details if available', action='store_true')
parser_describe.add_argument('dxid', help='Object ID to describe')
parser_describe.set_defaults(func=describe)

parser_close = subparsers.add_parser('close', help='Close a remote object', description='Close a remote object')
parser_close.add_argument('dxid', help='Object ID to close')
parser_close.add_argument('--block', help='Wait for the object to close', action='store_true')
parser_close.set_defaults(func=close)

parser_find = subparsers.add_parser('find', help='Search functionality over data objects, projects, and jobs',
                                    description='Search functionality over data objects, projects, and jobs')
subparsers_find = parser_find.add_subparsers()

parser_find_jobs = subparsers_find.add_parser('jobs', help='Finds jobs', parents=[global_args])
parser_find_jobs.add_argument('--user', help='User ID who launched the job')
parser_find_jobs.add_argument('--program', help='Program ID that job is running')
parser_find_jobs.add_argument('--project', help='Project context ID (output project)')
parser_find_jobs.add_argument('--state', help='State of the job, e.g. \"done\", \"failed\"')
parser_find_jobs.add_argument('--origin', help='Job ID of the top-level (user-initiated) job')
parser_find_jobs.add_argument('--parent', help='Job ID of the parent job, or the string \'none\' to indicate no parent')
parser_find_jobs.add_argument('--nodesc', help='Only return job IDs', action='store_false') # flag stored as true = use describe
parser_find_jobs.add_argument('--mod_after', type=int, help='Timestamp after which the job was last modified (negative number means ms in the past)')
parser_find_jobs.add_argument('--mod_before', type=int, help='Timestamp before which the job was last modified (negative number means ms in the past)')
parser_find_jobs.set_defaults(func=find_jobs)

parser_find_data = subparsers_find.add_parser('data', help='Finds data objects', parents=[global_args])
parser_find_data.add_argument('--class', dest='classname', choices=['record', 'file', 'gtable', 'program', 'table'], help='Data object class')
parser_find_data.add_argument('--state', choices=['open', 'closing', 'closed', 'any'], help='State of the object')
parser_find_data.add_argument('--visibility', choices=['hidden', 'visible', 'either'], default='visible', help='Whether the object is hidden or not')
parser_find_data.add_argument('--name', help='Name of the object')
parser_find_data.add_argument('--properties', nargs='+', help='Key-value pairs of properties, e.g. \'--properties property_key property_value another_property_key another_property_value\'')
parser_find_data.add_argument('--type', help='Type of the data object')
parser_find_data.add_argument('--tag', help='Tag of the data object')
parser_find_data.add_argument('--link', help='Object ID that the data object links to')
parser_find_data.add_argument('--project', help='Project with which to restrict the results')
parser_find_data.add_argument('--folder', help='Folder path with which to restrict the results (\'--project\' must be used in this case)')
parser_find_data.add_argument('--recurse', help='Recurse into subfolders', action='store_true')
parser_find_data.add_argument('--mod_after', type=int, help='Timestamp after which the object was last modified (negative number means ms in the past)')
parser_find_data.add_argument('--mod_before', type=int, help='Timestamp before which the object was last modified (negative number means ms in the past)')
parser_find_data.add_argument('--created_after', type=int, help='Timestamp after which the object was created (negative number means ms in the past)')
parser_find_data.add_argument('--created_before', type=int, help='Timestamp before which the object was created (negative number means ms in the past)')
parser_find_data.add_argument('--describe', help='Also return descriptions of objects', action='store_true')
parser_find_data.set_defaults(func=find_data)

parser_dataobject_args = argparse.ArgumentParser(add_help=False)
parser_dataobject_args.add_argument('--visibility', choices=['hidden', 'visible'], default='visible', help='Whether the object is hidden or not')
parser_dataobject_args.add_argument('--name', help='Name of the object')
parser_dataobject_args.add_argument('--properties', nargs='+', help='Key-value pairs of properties, e.g. \'--properties property_key property_value another_property_key another_property_value\'')
parser_dataobject_args.add_argument('--types', nargs='+', help='Types of the data object')
parser_dataobject_args.add_argument('--tags', nargs='+', help='Tags of the data object')
parser_dataobject_args.add_argument('--project', help='Project (if not using the default project)')
parser_dataobject_args.add_argument('--details', help='JSON to store as details')
parser_dataobject_args.add_argument('--parents', help='Create folder (and its parents) if necessary', action='store_true')
parser_dataobject_args.add_argument('--folder', help='Folder path with which to restrict the results (\'--project\' must be used in this case)')

parser_new = subparsers.add_parser('new', help='Create a new data object')
subparsers_new = parser_new.add_subparsers()

parser_new_record = subparsers_new.add_parser('record', help='Create a new record',
                                              parents=[parser_dataobject_args])
parser_new_record.add_argument('--init', help='Record ID from which to initialize all metadata')
parser_new_record.set_defaults(func=new_record)

parser_new_gtable = subparsers_new.add_parser('gtable', help='Create a new gtable', parents=[parser_dataobject_args])
parser_new_gtable.add_argument('--columns', help='JSON for specifying the columns')
parser_new_gtable.add_argument('--indices', help='JSON for specifying the indices')
parser_new_gtable.add_argument('--input', help='a filename containing the JSON input to be used (currently only used for overriding --columns and --indices)')
parser_new_gtable.set_defaults(func=new_gtable)

parser_set_details = subparsers.add_parser('set_details', help='Set details on an object')
parser_set_details.add_argument('dxid', help='Data object to modify')
parser_set_details.add_argument('details', help='JSON to store as details')
parser_set_details.set_defaults(func=set_details)

parser_set_visibility = subparsers.add_parser('set_visibility', help='Set visibility on an object')
parser_set_visibility.add_argument('dxid', help='Data object to modify')
parser_set_visibility.add_argument('visibility', choices=['hidden', 'visible'], help='Visibility that the object should have')
parser_set_visibility.set_defaults(func=set_visibility)

parser_add_types = subparsers.add_parser('add_types', help='Add types to an object')
parser_add_types.add_argument('dxid', help='Data object to modify')
parser_add_types.add_argument('types', nargs='+', help='Types to add')
parser_add_types.set_defaults(func=add_types)

parser_remove_types = subparsers.add_parser('remove_types', help='Remove types from an object')
parser_remove_types.add_argument('dxid', help='Data object to modify')
parser_remove_types.add_argument('types', nargs='+', help='Types to remove')
parser_remove_types.set_defaults(func=remove_types)

parser_add_tags = subparsers.add_parser('add_tags', help='Add tags to an object')
parser_add_tags.add_argument('dxid', help='Data object to modify')
parser_add_tags.add_argument('tags', nargs='+', help='Tags to add')
parser_add_tags.set_defaults(func=add_tags)

parser_remove_tags = subparsers.add_parser('remove_tags', help='Remove tags from an object')
parser_remove_tags.add_argument('dxid', help='Data object to modify')
parser_remove_tags.add_argument('tags', nargs='+', help='Tags to remove')
parser_remove_tags.set_defaults(func=remove_tags)

parser_rename = subparsers.add_parser('rename', help='Rename an object')
parser_rename.add_argument('dxid', help='Data object to modify')
parser_rename.add_argument('name', help='New name')
parser_rename.set_defaults(func=rename)

parser_set_properties = subparsers.add_parser('set_properties', help='Set properties of an object')
parser_set_properties.add_argument('dxid', help='Data object to modify')
parser_set_properties.add_argument('properties', nargs='+', help='Key-value pairs of properties, e.g. \'--properties property_key property_value another_property_key another_property_value\'')
parser_set_properties.set_defaults(func=set_properties)

parser_unset_properties = subparsers.add_parser('unset_properties', help='Unset properties of an object')
parser_unset_properties.add_argument('dxid', help='Data object to modify')
parser_unset_properties.add_argument('properties', nargs='+', help='Property names to unset')
parser_unset_properties.set_defaults(func=unset_properties)

parser_api = subparsers.add_parser('api', help='Make an API call')
parser_api.add_argument('resource', help='is one of \"system\", a class name (e.g. \"record\"), or an entity ID such as \"record-xxxx\"')
parser_api.add_argument('method', help='a valid method for the resource as documented by the API document')
parser_api.add_argument('input_json', nargs='?', default="{}", help='the JSON input for the method as documented by the API document (if not given, \"{}\" is used)')
parser_api.add_argument('--input', help='a filename containing the JSON input to be used (takes precedence over the \'json\' argument)')
parser_api.add_argument('--stdin', help='Indicate that JSON input will be provided with a prompt', action='store_true')
parser_api.set_defaults(func=api)

args = parser.parse_args(sys.argv[1:])
args.func(args)
