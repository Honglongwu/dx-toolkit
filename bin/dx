#!/usr/bin/env python

import sys, os, datetime, urlparse, requests, base64, getpass
import urllib
import argparse
import shlex # respects quotes substrings when splitting
import textwrap
import re
from requests.auth import HTTPBasicAuth

import json

try:
    import readline
except ImportError:
    print 'readline module not available'

state = {"interactive": False}
parser_map = {}

class ResultCounter():
    def __init__(self):
        self.counter = 0

    def __call__(self):
        self.counter += 1
        return ('\n' if self.counter > 1 else '') + UNDERLINE + 'Result ' + \
            str(self.counter) + ':' + ENDC

def fill(string, width=80, **kwargs):
    return textwrap.fill(string, width=width, break_on_hyphens=False, **kwargs)

CYAN = '\033[36m'
BLUE = '\033[34m'
YELLOW = '\033[33m'
GREEN = '\033[32m'
RED = '\033[31m'
UNDERLINE = '\033[4m'
BOLD = '\033[1m'
ENDC = '\033[0m'

JOB_STATES = {'failed': BOLD + RED + 'failed' + ENDC,
              'done': BOLD + GREEN + 'done' + ENDC,
              'running': GREEN + 'running' + ENDC,
              'idle': YELLOW + 'idle' + ENDC,
              'runnable': YELLOW + 'runnable' + ENDC,
              'waiting_on_inputs': YELLOW + 'waiting_on_inputs' + ENDC,
              'waiting_on_outputs': YELLOW + 'waiting_on_outputs' + ENDC
              }

DATA_STATES = {'open': YELLOW + 'open' + ENDC,
               'closing': YELLOW + 'open' + ENDC,
               'closed': GREEN + 'closed' + ENDC
               }

data_obj_pattern = re.compile('^(record|table|gtable|program|file)-[0-9A-Za-z]{24}$')
hash_pattern = re.compile('^(record|table|gtable|app|program|job|project|workspace|container|file)-[0-9A-Za-z]{24}$')
nohash_pattern = re.compile('^(user|org|app|team)-')

# TODO: Should we cache the user ID entered in the login phase?  or put it in an environment variable?

# TODO: Concept of local profiles: default username, project, folder, set of aliases, option to save current state to a particular profile

# The following caches project names to project IDs
cached_project_names = {}
# The following caches project IDs to a hash of folder paths to a hash of names to data object IDs
cached_project_paths = {}
# The following caches aliases that the user defines to a hash of {"project": project-ID, "id": object-ID} (with the "project" key optional)
# TODO: Allow option for saving these aliases for a future session under a particular profile, perhaps
cached_aliases = {}

def is_hashid(string):
    return hash_pattern.match(string) is not None

def is_data_obj_id(string):
    return data_obj_pattern.match(string) is not None

def is_container_id(string):
    return is_hashid(string) and (string.startswith('project-') or string.startswith('workspace-') or string.startswith('container-'))

def is_nohash_id(string):
    return nohash_pattern.match(string) is not None

def escape_folder_str(string):
    return string.replace('\\', '\\\\').replace(' ', '\ ').replace(':', '\:')

def escape_name_str(string):
    return string.replace('\\', '\\\\').replace(' ', '\ ').replace(':', '\:').replace('/', '\/')

def unescape_folder_str(string):
    return string.replace('\:', ':').replace('\ ', ' ').replace('\\\\', '\\')

def unescape_name_str(string):
    return string.replace('\:', ':').replace('\ ', ' ').replace('\/', '/').replace('\\\\', '\\')

def get_last_pos_of_char(char, string):
    pos = len(string)
    while pos > 0:
        pos = string[:pos].rfind(char)
        if pos == -1:
            return -1
        num_backslashes = 0
        test_index = pos - 1
        while test_index >= 0 and string[test_index] == '\\':
            num_backslashes += 1
            test_index -= 1
        if num_backslashes % 2 == 0:
            return pos
    return -1

# Does not return the empty string
def split_unescaped(char, string):
    words = []
    pos = len(string)
    lastpos = pos
    while pos >= 0:
        pos = get_last_pos_of_char(char, string[:lastpos])
        if pos >= 0:
            if pos + 1 != lastpos:
                words.append(string[pos + 1: lastpos])
            lastpos = pos
    if lastpos != 0:
        words.append(string[:lastpos])
    words.reverse()
    return words

# expected is one of "entity", "folder", or None
def clean_folder_path(path, expected=None):
    folders = split_unescaped('/', path)

    if len(folders) == 0:
        return '/', None

    if expected == 'folder' or folders[-1] == '.' or folders[-1] == '..' or get_last_pos_of_char('/', path) == len(path) - 1:
        entity_name = None
    else:
        entity_name = unescape_name_str(folders[-1])
        folders = folders[:-1]

    sanitized_folders = []

    for folder in folders:
        if folder == '.':
            pass
        elif folder == '..':
            if len(sanitized_folders) > 0:
                sanitized_folders.pop()
        else:
            sanitized_folders.append(unescape_folder_str(folder))

    if len(sanitized_folders) == 0:
        newpath = '/'
    else:
        newpath = ""
        for folder in sanitized_folders:
            newpath += '/' + folder

    return newpath, entity_name

# INPUTS
# choices: list of strings that will be presented as choices
# default: default index of choices
# OUTPUTS
# index of choices to be used
def pick(choices, default=None):
    for i in range(len(choices)):
        print str(i) + ') ' + choices[i]
    print ''
    if default is not None:
        prompt = 'Pick a numbered choice [' + str(default) + ']: '
    else:
        prompt = 'Pick a numbered choice: '
    while True:
        try: 
            value = raw_input(prompt)
        except KeyboardInterrupt:
            print ''
            continue
        except EOFError:
            print ''
            parser.exit(1)
        if default is not None and value == '':
            return default
        try:
            choice = int(value)
            if choice not in range(len(choices)):
                raise IndexError()
            return choice
        except BaseException as details:
            print str(details)
            print 'Not a valid selection'

# raw_string: escaped name string
# is_error: exit parser if it cannot be resolved.  otherwise, return None
def resolve_container_id_or_name(raw_string, is_error=False, unescape=True):
    if unescape:
        string = unescape_name_str(raw_string)
    if is_container_id(string):
        return string

    if string in cached_project_names:
        return cached_project_names[string]

    try:
        results = list(dxpy.find_projects(name=string, describe=True))
    except BaseException as details:
        parser.exit(1, fill(str(details)) + '\n')

    if len(results) == 1:
        cached_project_names[string] = results[0]['id']
        return results[0]['id']
    elif len(results) > 1:
        print 'Found multiple projects with name \"' + string + '\"'
        choice = pick(map(lambda result: result['id'] + ' (' + result['level'] + ')', results))
        return results[choice]['id']
    else:
        if is_error:
            parser.exit(1, 'Could not resolve container ID or name\n')
        return None

# INPUTS
# - path: a path, e.g. "project-name:folder/path/objectname"
# - expected: "folder" if only interested in a folder, "entity" if only interested in first-class entities
#
# OUTPUTS
# - project: None if no current default project is found
# - folderpath: folder path except for last name or None if path is a hash ID
# - entity_name: sanitized name of entity or None if expected is "folder"
#
# Will fatally exit if:
# - a colon is provided, but no project can be resolved
# - expected="folder" but no project can be resolved
# Will NOT fatally exit if:
# - folder or path to object does not exist
def resolve_path_with_project(path, expected=None):
    # Easy case: ":"
    if path == ':':
        if 'DX_PROJECT_CONTEXT_ID' not in os.environ:
            parser.exit(1, fill('Expected a project name or ID to the left of a colon or for a current project to be set.') + '\n')
        return os.environ['DX_PROJECT_CONTEXT_ID'], '/', None
    # Second easy case: hash ID
    if is_container_id(path):
        return path, '/', None
    elif is_hashid(path):
        return os.environ.get('DX_PROJECT_CONTEXT_ID', None), None, path

    project = None
    wd = None

    # Test for multiple colons
    last_colon = get_last_pos_of_char(':', path)
    if last_colon >= 0:
        last_last_colon = get_last_pos_of_char(':', path[:last_colon])
        if last_last_colon >= 0:
            parser.exit(1, 'At most one colon expected in a path\n')

    substrings = split_unescaped(':', path)

    if len(substrings) == 2:
        # project-name-or-id:folderpath/to/possible/entity
        project = resolve_container_id_or_name(substrings[0], is_error=True)
        wd = '/'
    elif get_last_pos_of_char(':', path) >= 0:
        # :folderpath/to/possible/entity OR project-name-or-id:
        # Colon is either at the beginning or at the end
        wd = '/'
        if path.startswith(':'):
            if 'DX_PROJECT_CONTEXT_ID' not in os.environ:
                parser.exit(1, fill('Expected a project name or ID to the left of a colon or for a current project to be set') + '\n')
            project = os.environ['DX_PROJECT_CONTEXT_ID']
        else:
            # One nonempty string to the left of a colon
            project = resolve_container_id_or_name(substrings[0], is_error=True)
            return project, '/', None
    else:
        # One nonempty string, no colon present, do NOT interpret as
        # project
        project = os.environ.get('DX_PROJECT_CONTEXT_ID', None)
        if expected == 'folder' and project is None:
            parser.exit(1, 'Could not resolve a project name or ID\n')
        wd = os.environ.get('DX_CLI_WD', '/')

    # Determine folderpath and entity_name if necessary
    folderpath = substrings[-1]
    folderpath, entity_name = clean_folder_path(wd + '/' + folderpath, expected)

    return project, folderpath, entity_name

# Returns either a list of results or a single result (depending on
# how many is expected; if only one, then an interactive picking of a
# choice will be initiated).
# Output is of the form {"id": id, "describe": describe hash}
# TODO: Allow arbitrary flags for the describe hash.
def resolve_existing_path(path, expected=None, only_one=True):
    project, folderpath, entity_name = resolve_path_with_project(path, expected)
    if entity_name is None:
        # Definitely a folder (or project)
        # FIXME? Should I check that the folder exists if expected="folder"?
        return project, folderpath, entity_name
    elif is_hashid(entity_name):
        try:
            desc = dxpy.DXHTTPRequest('/' + entity_name + '/describe', {})
        except BaseException as details:
            parser.exit(1, fill(str(details)) + '\n')
        result = {"id": entity_name, "describe": desc}
        if only_one:
            return project, folderpath, result
        else:
            return project, folderpath, [result]
    else:
        msg = fill('Object of name ' + entity_name + ' could not be resolved in folder ' + folderpath + ' of project ID ' + project) + '\n'
        # Probably an object
        try:
            results = list(dxpy.find_data_objects(project=project,
                                                  folder=folderpath,
                                                  name=entity_name,
                                                  recurse=False,
                                                  describe=True))
        except BaseException as details:
            parser.exit(1, fill(str(details)) + '\n')
        if len(results) == 0:
            # Could not find it as a data object.  If anything, it's a
            # folder.

            if '/' in entity_name:
                # Then there's no way it's supposed to be a folder
                parser.exit(1, msg)

            # This is the only possibility left.  Leave the
            # error-checking for later.  Note that folderpath does
            possible_folder = folderpath + '/' + entity_name
            possible_folder, skip = clean_folder_path(possible_folder, 'folder')
            return project, possible_folder, None

        # Caller is okay with multiple results; just return the whole thing
        if not only_one:
            return project, None, results

        if len(results) > 1:
            print 'The given path \"' + path + '\" resolves to the following data objects:'
            choice = pick(map(lambda result:
                                  get_ls_l_desc(result['describe']),
                              results))
            return project, None, results[choice]
        elif len(results) == 1:
            return project, None, results[0]

def grab_contents_of_folder(completer, folder):
    # Only refresh lists if the current folder is not the one
    try:
        resp = completer.dxproj.list_folder(folder=folder, describe={},
                                            includeHidden=True)
        completer.folders = ['../', './'] + map(lambda folder: escape_folder_str(os.path.basename(folder)) + '/', resp['folders'])
        completer.names = map(lambda result: escape_name_str(result['describe']['name']) + ' ', resp['objects'])

        if proj_id not in cached_project_paths:
            cached_project_paths[proj_id] = {}
        cached_project_paths[proj_id][folder] = {}
        for obj in resp['objects']:
            obj_name = obj['describe']['name']
            if obj_name not in cached_project_paths[proj_id][folder]:
                cached_project_paths[proj_id][folder][obj_name] = [obj['id']]
            else:
                cached_project_paths[proj_id][folder][obj_name].append(obj['id'])
    except:
        pass

def get_project_and_folder_content_matches(completer, words):
    start_pos = 0
    if completer.last_slash_pos is not None:
        start_pos = completer.last_slash_pos + 1
    elif completer.colon_pos is not None:
        # project already filled in
        start_pos = completer.colon_pos + 1
    if len(words) > 0:
        true_prefix = words[-1][start_pos:]
        done_prefix = ' '.join(words[:-1]) + ' ' + words[-1][:start_pos]
    else:
        true_prefix = ''
        done_prefix = ''
    completer.matches = filter(lambda folder: folder.startswith(true_prefix) and (true_prefix != '' or folder not in ['../', './']), completer.folders) + \
        filter(lambda name: name.startswith(true_prefix), completer.names) + \
        filter(lambda proj_name: proj_name.startswith(true_prefix), completer.project_names)
    completer.matches = map(lambda match: done_prefix + match, completer.matches)

def basename(string):
    pos = get_last_pos_of_char('/', string)
    if pos >= 0:
        return unescape_name_str(string[pos+1:])
    else:
        return unescape_name_str(string)

def obj_completer(completer, current_line, words):
    completer.dxproj = None

    # First get projects if necessary
    colon_pos = -1
    project = None
    if len(words) > 0:
        colon_pos = get_last_pos_of_char(':', words[-1])
#        print 'colon index: ' + str(colon_pos)
    if colon_pos < 0:
        # Might be tab-completing a project
        results = list(dxpy.find_projects(describe=True))
        completer.project_names = map(lambda result: escape_name_str(result['describe']['name']) + ':', results)
        if 'DX_PROJECT_CONTEXT_ID' in os.environ:
            completer.dxproj = dxpy.get_handler(os.environ['DX_PROJECT_CONTEXT_ID'])
    else:
        project = unescape_name_str(words[-1][:colon_pos])
        try:
            completer.dxproj = dxpy.get_handler(project)
        except:
            results = list(dxpy.find_projects(name=project))
            if len(results) == 1:
                completer.dxproj = dxpy.DXProject(results[0]['id'])
                completer.project_names = []
            elif len(results) > 1:
                print 'Found ' + str(len(results)) + ' projects with name ' + project + ':'
                for result in results:
                    print result['id']
                parser.exit(1)
            else:
                parser.exit(1, 'Could not resolve project name\n')

    # Then get path to current folder if we have some project to look in
    if completer.dxproj is not None:
        path = os.environ['DX_CLI_WD']
        last_slash_pos = -1
        if len(words) > 0:
            last_slash_pos = get_last_pos_of_char('/', words[-1])
        if last_slash_pos >= 0:
            if colon_pos >= 0:
                path += '/' + unescape_folder_str(words[-1][colon_pos + 1 : last_slash_pos])
            else:
                path += '/' + unescape_folder_str(words[-1][:last_slash_pos])
#        print 'looking in path ' + path
        # Then update lists as necessary
        grab_contents_of_folder(completer, resolve_path(path))

    # TODO: Then look for app names???

    completer.colon_pos = colon_pos
    completer.last_slash_pos = last_slash_pos

# This completer assumes you're trying to enter an object
class DXObjectCompleter():
    def __init__(self, classes=None):
        self.dxproj = None
        self.project_names = None
        self.folders = None
        self.names = None
        self.colon_pos = -1
        self.last_slash_pos = -1
        self.matches = None
        self.classes = classes

    def __call__(self, text, state):
        if state == 0:
            current_line = readline.get_line_buffer()
            words = split_unescaped(' ', current_line)
            obj_completer(self, current_line, words)
            # Then find matches
            get_project_and_folder_content_matches(self, words)

        if self.matches is not None and state < len(self.matches):
            return self.matches[state]
        else:
            return None

# This completer is for the command-line in the shell.  It assumes the
# first word is always a subcommand and that if the first word is a
# subcommand with further subcommands, then the second word must be an
# appropriate sub-subcommand.
class DXCLICompleter():    
    subsubcommands = {'file': ['get ', 'put '],
                      'gtable': ['get '],
                      'find': ['jobs ', 'data ', 'projects ', 'apps '],
                      'new': ['record ', 'gtable ']}

    def __init__(self):
        global subparsers
        self.subcommands = map(lambda subcmd: subcmd + ' ', subparsers.choices.keys())
        self.dxproj = None
        self.project_names = None
        self.folders = None
        self.names = None
        self.colon_pos = -1
        self.last_slash_pos = -1
        self.matches = None

    def get_subcommand_matches(self, prefix):
        self.matches = filter(lambda subcommand: subcommand.startswith(prefix),
                              self.subcommands)

    def get_subsubcommand_matches(self, subcommand, prefix):
        if subcommand in self.subsubcommands:
            self.matches = map(lambda subsub: subcommand + ' ' + subsub,
                               filter(lambda subsubcommand: subsubcommand.startswith(prefix),
                                      self.subsubcommands[subcommand]))

    def __call__(self, text, state):
        if state == 0:
            current_line = readline.get_line_buffer()
            words = split_unescaped(' ', current_line)
            if len(words) > 0 and current_line[-1] == ' ':
                words.append('')
            num_words = len(words)
            self.matches = None
            if num_words == 0:
                self.get_subcommand_matches('')
            elif num_words == 1:
                self.get_subcommand_matches(words[0])
            elif num_words == 2 and words[0] in self.subsubcommands:
                self.get_subsubcommand_matches(words[0], words[1])
            else:
                obj_completer(self, current_line, words)
                # Then find matches
                get_project_and_folder_content_matches(self, words)

        if self.matches is not None and state < len(self.matches):
            return self.matches[state]
        else:
            return None

def get_bash_export_cmds(env_vars):
    string = ''
    for var in env_vars:
        string += 'export ' + var + '=' + "'" + env_vars[var] + "'\n"
    return string

def parse_env_file():
    env_vars = {}
    try:
        with open(os.path.expanduser('~/.dnanexus/environment'), 'r') as fd:
            for line in fd:
                if line.startswith('export '):
                    env_vars[line[7: line.find('=')]] = ''.join(shlex.split(line[line.find('=') + 1:]))
    except:
        pass
    return env_vars

def write_env_var(var, value):
    try:
        os.mkdir(os.path.expanduser('~/.dnanexus/'))
    except:
        pass
    env_vars = parse_env_file()
    env_vars[var] = value
    with open(os.path.expanduser('~/.dnanexus/') + 'environment', 'w') as fd:
        fd.write(fill('This file is automatically generated by the DNAnexus Command-line Client dx.  Edit it at your own risk.  See documentation on the CLI and environment variables for more information.', initial_indent='# ', subsequent_indent='# ') + '\n\n')
        fd.write(get_bash_export_cmds(env_vars))

def load_env():
    already_set = []
    env_vars = parse_env_file()
    for var in env_vars:
        # TODO: Find out how bad the line below is for Mac OS X.
        if var in os.environ:
            if os.environ[var] != env_vars[var]:
                already_set.append(var)
            else:
                pass
        else:
            os.environ[var] = env_vars[var]

    if len(already_set) > 0 and sys.stdin.isatty():
        print fill("WARNING: The following environment variables were found to be different than the values last stored by dx.  To use the values stored by dx, run \"source ~/.dnanexus/environment\" to set your environment variables in your shell.  To clear the dx-stored values, run \"dx clearenv\"")
        print '  ' + '\n  '.join(already_set)

    if 'DX_CLI_WD' not in os.environ:
        write_env_var("DX_CLI_WD", '/')
        os.environ['DX_CLI_WD'] = '/'

def clearenv(args):
    try:
        os.remove(os.path.expanduser('~/.dnanexus/environment'))
    except:
        pass

def get_json_from_stdin():
    user_json_str = raw_input('Type JSON here> ')
    user_json = None
    try:
        user_json = json.loads(user_json_str)
    except:
        parser.exit(1, 'Error: user input could not be parsed as JSON\n')
        return None
    return user_json

# Loading environment

args_list = sys.argv[1:]

# Hard-coding a shortcut so that it won't print out the warning in
# load_env when clearing it anyway.
if len(args_list) == 1 and args_list[0] == 'clearenv':
    clearenv(argparse.Namespace())
    exit(0)

load_env()

# IMPORTANT: Import dxpy AFTER loading environment variables
import dxpy

def login(args):
    if not state['interactive']:
        args.save = True

    # TODO: Remove this and replace with actual logic and interaction
    # when implemented
    if args.host is not None or args.port is not None:
        authserver = 'http://' + args.host
        authserver += ':' + str(args.port)
        print 'Acquiring credentials from ' + authserver

        username = raw_input('Username: ')
        password = getpass.getpass()

        session = requests.session()

        response = ""
        try:
            response = session.post(authserver + "/direct_token", data={"grant_type": "authorization_code", "redirect_uri": "/"}, headers={"Authorization": "Basic " + base64.b64encode(username + ":" + password)})
            response.raise_for_status()
        except requests.exceptions.RequestException as details:
            print 'Error contacting the auth server: ' + str(details)
            parser.exit(1)
        token = json.loads(response.content)["access_token"]
        sec_context = '{"auth_token":"' + token + '","auth_token_type":"Bearer"}'
    elif args.token is None:
        authserver = 'https://auth.dnanexus.com'
        print 'Acquiring credentials from ' + authserver

        try:
            username = raw_input('Username: ')
            password = getpass.getpass()
        except:
            print ''
            parser.exit(1)
        auth = HTTPBasicAuth(username, password)

        session = requests.session()
        res = requests.post(authserver+"/oauth2/authorize",
                            data={"response_type": "code", "client_id": "test", "redirect_uri": "/"},
                            auth=auth,
                            allow_redirects=False)
        parsed_url = urlparse.parse_qs(urlparse.urlsplit(res.headers['Location'])[3])
        if 'code' not in parsed_url:
            parser.exit(1, 'Error: Incorrect username and/or password\n')
        else:
            code = parsed_url['code'][0]
        
        res = requests.post(authserver+"/oauth2/token",
                            data={"grant_type": "authorization_code", "code": code, "redirect_uri": "/"})
        assert(res.status_code == requests.codes.ok)
        token_res = json.loads(res.content)
        sec_context=json.dumps({'auth_token': token_res["access_token"], 'auth_token_type': token_res["token_type"]})
    else:
        sec_context = '{"auth_token":"' + args.token + '","auth_token_type":"Bearer"}'

    dxpy.set_security_context(json.loads(sec_context))

    set_auth_token(sec_context=sec_context, write=args.save)
    args.current = False
    setenv(args)

def logout(args):
    write_env_var('DX_SECURITY_CONTEXT', '')

def set_auth_token(token=None, sec_context=None, write=False):
    if token is not None:
        os.environ['DX_SECURITY_CONTEXT'] = '{"auth_token":"' + token + '","auth_token_type":"Bearer"}'
    elif sec_context is not None:
        os.environ['DX_SECURITY_CONTEXT'] = sec_context
    else:
        parser.exit(1, 'Error: set_auth_token was called with no token nor security context hash\n')
    if write:
        write_env_var('DX_SECURITY_CONTEXT', sec_context)

def set_api(protocol, host, port, write):
    os.environ['DX_APISERVER_PROTOCOL'] = protocol
    os.environ['DX_APISERVER_HOST'] = host
    os.environ['DX_APISERVER_PORT'] = port
    if write:
        write_env_var("DX_APISERVER_PROTOCOL", protocol)
        write_env_var("DX_APISERVER_HOST", host)
        write_env_var("DX_APISERVER_PORT", port)
    dxpy.set_api_server_info(host=host, port=port, protocol=protocol)

def set_project(project, write):
    os.environ['DX_PROJECT_CONTEXT_ID'] = project
    if write:
        write_env_var("DX_PROJECT_CONTEXT_ID", project)
    dxpy.set_workspace_id(project)

def set_wd(folder, write):
    os.environ['DX_CLI_WD'] = folder
    if write:
        write_env_var("DX_CLI_WD", folder)

def prompt_for_var(prompt_str, env_var_str):
    prompt = prompt_str
    default = None
    if env_var_str in os.environ:
        default = os.environ[env_var_str]
        prompt += ' [' + default + ']: '
    else:
        prompt += ': '
    while True:
        try: 
            value = raw_input(prompt)
        except KeyboardInterrupt:
            print ''
            continue
        except EOFError:
            print ''
            raise EOFError()
        if value != '':
            return value
        elif default is not None:
            return default

def pick_and_set_project(args):
    try:
        results = list(dxpy.find_projects(describe=True))
    except BaseException as details:
        parser.exit(1, fill('Error when listing available projects: ' + str(details)) + '\n')

    projects = map(lambda result: result['id'], results)
    if len(projects) == 0:
        parser.exit(1, 'No projects to choose from.  Please create one first using "dx new project".\n')

    # Eliminate current default if it is not a found project
    try:
        default = projects.index(os.environ.get('DX_PROJECT_CONTEXT_ID', None))
    except:
        default = None

    print ""
    print "Available projects:"
    choice = pick(
        map(lambda result:
                result['describe']['name'] + ' (' + result['level'] + ')',
            results),
        default)

    print 'Setting current project to: ' + results[choice]['describe']['name']
    set_project(projects[choice], not state['interactive'])
    set_wd('/', not state['interactive'])

def setenv(args):
    if not state['interactive']:
        args.save = True
    if args.current:
        env_vars = ['DX_SECURITY_CONTEXT', 'DX_APISERVER_HOST', 'DX_APISERVER_PORT', 'DX_PROJECT_CONTEXT_ID', 'DX_CLI_WD']
        for var in env_vars:
            if var in os.environ:
                write_env_var(var, os.environ[var])
    else:
        api_protocol = prompt_for_var('API server protocol (choose "http" or "https")', 'DX_APISERVER_PROTOCOL')
        api_host = prompt_for_var('API server host', 'DX_APISERVER_HOST')
        api_port = prompt_for_var('API server port', 'DX_APISERVER_PORT')
        set_api(api_protocol, api_host, api_port, args.save)

    if args.projects:
        pick_and_set_project(args)

def env(args):
    if args.bash:
        if 'DX_SECURITY_CONTEXT' in os.environ:
            print "export DX_SECURITY_CONTEXT='" + os.environ['DX_SECURITY_CONTEXT'] + "'"
        if 'DX_APISERVER_PROTOCOL' in os.environ:
            print "export DX_APISERVER_PROTOCOL=" + os.environ['DX_APISERVER_PROTOCOL']
        if 'DX_APISERVER_HOST' in os.environ:
            print "export DX_APISERVER_HOST=" + os.environ['DX_APISERVER_HOST']
        if 'DX_APISERVER_PORT' in os.environ:
            print "export DX_APISERVER_PORT=" + os.environ['DX_APISERVER_PORT']
    else:
        print "Auth token used\t\t" + str(json.loads(os.environ.get("DX_SECURITY_CONTEXT", "{\"auth_token\": null}"))["auth_token"])
        print "API server protocol\t" + str(os.environ.get("DX_APISERVER_PROTOCOL"))
        print "API server host\t\t" + str(os.environ.get("DX_APISERVER_HOST"))
        print "API server port\t\t" + str(os.environ.get("DX_APISERVER_PORT"))
        print "Current workspace\t" + str(os.environ.get("DX_PROJECT_CONTEXT_ID"))
        print "Current folder\t\t" + str(os.environ.get("DX_CLI_WD"))

def pwd(args):
    print os.environ['DX_CLI_WD']

def api(args):
    json_input = json.loads(args.input_json)
    if args.input is not None:
        with open(args.input, 'r') as fd:
            data = fd.read()
            try:
                json_input = json.loads(data)
            except:
                parser.exit(1, 'Error: file contents could not be parsed as JSON\n')
    elif args.stdin:
        json_input = get_json_from_stdin()
        if json_input == None:
            return
    resp = None
    try:
        resp = dxpy.DXHTTPRequest('/' + args.resource + '/' + args.method,
                                  json_input)
        print json.dumps(resp, indent=4)
    except dxpy.DXAPIError as details:
        parser.exit(1, fill(str(details)) + '\n')

def get_app_from_path(path):
    alias = None
    if not path.startswith('app-'):
        path = 'app-' + path
    if '/' in path:
        alias = path[path.find('/') + 1:]
        path = path[:path.find('/')]
    try:
        if alias is None:
            desc = dxpy.DXHTTPRequest('/' + path + '/describe', {})
        else:
            desc = dxpy.DXHTTPRequest('/' + path + '/' + alias + '/describe', {})
        return desc
    except dxpy.DXAPIError as details:
        return None

def cd(args):
    # entity_result should be None because expected='folder'
    project, folderpath, none = resolve_existing_path(args.path, 'folder')

    if project is not None:
        # It is obvious what the project is
        if project != os.environ.get('DX_PROJECT_CONTEXT_ID', None):
            # And it's different so we need to take action
            set_project(project, not state['interactive'])
    else:
        parser.exit(1, 'Error: No current project was given\n')

    # TODO: attempt to add caching later if it's an issue
    # if project in cached_project_paths and folderpath in cached_project_paths[project]:
    #     set_wd(folderpath, not interactive)

    try:
        dxproj = dxpy.get_handler(os.environ['DX_PROJECT_CONTEXT_ID'])
        dxproj.list_folder(folder=folderpath)
    except:
        parser.exit(1, fill(folderpath + ': No such file or directory found in project ' + os.environ['DX_PROJECT_CONTEXT_ID']) + '\n')
        return

    set_wd(folderpath, not state['interactive'])

def cmp_names(x, y):
    return cmp(x['describe']['name'].lower(), y['describe']['name'].lower())    

def get_ls_l_desc(desc):
    if desc['state'] != 'closed':
        state_str = YELLOW + desc['state'] + ENDC
    else:
        state_str = GREEN + desc['state'] + ENDC

    if desc['class'] == 'program':
        name_str = BOLD + GREEN + desc['name'] + ENDC
    else:
        name_str = desc['name']

    return state_str + ' '*(8-len(desc['state'])) + str(datetime.datetime.fromtimestamp(desc['modified']/1000)) + '  ' + name_str + ' (' + desc['id'] + ')'

def print_ls_l_desc(desc):
    print get_ls_l_desc(desc)

def ls(args):
    project, folderpath, entity_results = resolve_existing_path(args.path, only_one=False)

    if project is None:
        parser.exit(1, fill('Current project must be set or specified before any data can be listed') + '\n')
    dxproj = dxpy.get_handler(project)
    only = ""
    if args.obj and not args.folders and not args.full:
        only = "objects"
    elif not args.obj and args.folders and not args.full:
        only = "folders"
    else:
        only = "all"

    resp = None
    if entity_results is None:
        try:
            resp = dxproj.list_folder(folder=folderpath,
                                      describe={},
                                      only=only,
                                      includeHidden=args.all)

            # Listing the folder was successful

            if args.l:
                print UNDERLINE + 'Project:' + ENDC + ' ' + dxproj.describe()['name'] + ' (' + project + ')'
                print UNDERLINE + 'Folder :' + ENDC + ' ' + folderpath

            if not args.obj:
                for folder in resp["folders"]:
                    if args.full:
                        print BOLD + BLUE + folder + ENDC
                    else:
                        print BOLD + BLUE + os.path.basename(folder) + '/' + ENDC
            if not args.folders:
                if project not in cached_project_paths:
                    cached_project_paths[project] = {}
                cached_project_paths[project][folderpath] = {}

                resp["objects"].sort(cmp=cmp_names)
                last_name = None
                next_name = None
                if args.l:
                    if len(resp['objects']) > 0:
                        print BOLD + 'State\tLast modified\t     Name (ID)' + ENDC
                    else:
                        print "No data objects found in the folder"
                for i in range(len(resp["objects"])):
                    current_name = resp['objects'][i]['describe']['name']
                    if i < len(resp['objects']) - 1:
                        next_name = resp['objects'][i + 1]['describe']['name']
                    else:
                        next_name = None
                    addendum = ''

                    if last_name is not None and last_name == current_name:
                        addendum = ' : ' + resp['objects'][i]['id']
                        cached_project_paths[project][folderpath][current_name].append(resp['objects'][i]['id'])
                    else:
                        cached_project_paths[project][folderpath][current_name] = [resp['objects'][i]['id']]
                        if next_name is not None and current_name == next_name:
                            addendum = ' : ' + resp['objects'][i]['id']

                    if args.l:
                        print_ls_l_desc(resp['objects'][i]['describe'])
                    else:
                        if resp['objects'][i]['describe']['class'] == 'program':
                            print BOLD + GREEN + resp['objects'][i]['describe']['name'] + ENDC + addendum
                        else:
                            print resp['objects'][i]['describe']['name'] + addendum

                    last_name = current_name
        except BaseException as details:
            parser.exit(1, fill(str(details)) + '\n')
    else:
        # We have results to describe
        for result in entity_results:
            print_ls_l_desc(result['describe'])

def mkdir(args):
    project, folderpath, none = resolve_path_with_project(args.path, expected='folder')

    dxproj = dxpy.get_handler(project)
    try:
        dxproj.new_folder(folder=folderpath, parents=args.parents)
    except dxpy.DXAPIError as details:
        parser.exit(1, fill(str(details)) + '\n')

def rmdir(args):
    project, folderpath, none = resolve_path_with_project(args.path, expected='folder')

    dxproj = dxpy.get_handler(project)
    try:
        dxproj.remove_folder(folder=folderpath)
    except dxpy.DXAPIError as details:
        parser.exit(1, fill(str(details)) + '\n')

def rm(args):
    projects = {}
    for path in args.paths:
        # Resolve the path and add it to the list
        project, folderpath, entity_result = resolve_existing_path(path)
        if project is None:
            parser.exit(1, fill('Could not resolve \"' + path + '\" to a project') + '\n')
        if project not in projects:
            projects[project] = {"folders": [], "objects": []}
        if entity_result is None:
            if folderpath is not None:
                if not args.recursive:
                    parser.exit(1, 'Cannot remove a folder without setting the \"-r\" flag\n')
                else:
                    projects[project]['folders'].append(folderpath)
            else:
                parser.exit(1, 'Cannot remove a project using \"rm\"')
        else:
            projects[project]['objects'].append(entity_result['id'])

    for project in projects:
        for folder in projects[project]['folders']:
            try:
                dxpy.DXHTTPRequest('/' + project + '/removeFolder',
                                   {"folder": folder,
                                    "recurse": True})
            except BaseException as details:
                print "Error while removing " + folder + " from " + project
                print "  " + str(details)
        try:
            dxpy.DXHTTPRequest('/' + project + '/removeObjects',
                               {"objects": projects[project]['objects']})
        except BaseException as details:
            print "Error while removing " + json.dumps(projects[project]['objects']) + " from " + project
            print "  " + str(details)

def rmproject(args):
    for project in args.projects:
        # Be forgiving if they offer an extraneous colon
        substrings = split_unescaped(':', project)
        if len(substrings) > 1 or (len(substrings) == 1 and project[0] == ':'):
            print fill('Was unable to remove \"' + project + '\": a nonempty string was found to the right of an unescaped colon')
            continue
        if len(substrings) == 0:
            if project[0] == ':':
                print fill('Unable to remove \":\": to remove the current project, use its name or ID')
                continue
        proj_id = resolve_container_id_or_name(substrings[0])
        if proj_id is None:
            print fill('Was unable to remove \"' + project + '\": could not resolve to a project ID')
            continue
        try:
            proj_desc = dxpy.DXHTTPRequest('/' + proj_id + '/describe', {})
            value = raw_input(fill('About to delete project \"' + proj_desc['name'] + '\" (' + proj_id + ')') + '\nPlease confirm [yes/no]: ')
            if value.lower() != 'yes':
                print fill('Aborting deletion of project \"' + proj_desc['name'] + '\"')
                continue
            dxpy.DXHTTPRequest('/' + proj_id + '/destroy', {})
            print fill('Successfully deleted project \"' + proj_desc['name'] + '\"')
        except EOFError:
            print ''
            parser.exit(1)
        except KeyboardInterrupt:
            print ''
            continue
        except BaseException as details:
            print fill('Was unable to remove ' + project + ', ' + str(details))

# ONLY for within the SAME project.  Will exit fatally otherwise.
def mv(args):
    try:
        dest_proj, dest_path, none = resolve_path_with_project(args.destination, 'folder')
        dx_dest = dxpy.get_handler(dest_proj)
        dx_dest.list_folder(folder=dest_path, only='folders')
    except:
        # Destination folder path is new => renaming
        if len(args.sources) != 1:
            # Can't rename more than one object
            parser.exit(1, 'The destination folder does not exist\n')
        last_slash_pos = get_last_pos_of_char('/', dest_path)
        if last_slash_pos == 0:
            dest_folder = '/'
        else:
            dest_folder = dest_path[:last_slash_pos]
        dest_name = dest_path[last_slash_pos + 1:].replace('\/', '/')
        try:
            dx_dest.list_folder(folder=dest_folder, only='folders')
        except:
            parser.exit(1, 'The destination folder does not exist\n')

        # Either rename the data object or rename the folder
        src_proj, src_path, src_result = resolve_existing_path(args.sources[0])

        if src_proj != dest_proj:
            parser.exit(1, 'Using \"mv\" for moving something from one project to another is unsupported.\n')

        if src_result is None:
            if src_path == '/':
                parser.exit(1, fill('Cannot rename root folder; to rename the project, use the "dx rename" subcommand.') + '\n')
            try:
                dxpy.DXHTTPRequest('/' + src_proj + '/renameFolder',
                                   {"folder": src_path,
                                    "newpath": dest_path})
                return
            except BaseException as details:
                parser.exit(1, fill(str(details)) + '\n')
        else:
            try:
                if src_result['describe']['folder'] != dest_folder:
                    dxpy.DXHTTPRequest('/' + src_proj + '/move',
                                       {"objects": [src_result['id']],
                                        "destination": dest_folder})
                dxpy.DXHTTPRequest('/' + src_result['id'] + '/rename',
                                   {"project": src_proj,
                                    "name": dest_name})
                return
            except BaseException as details:
                parser.exit(1, fill(str(details)) + '\n')

    src_objects = []
    src_folders = []
    for source in args.sources:
        src_proj, src_folderpath, src_result = resolve_existing_path(source)
        if src_proj != dest_proj:
            parser.exit(1, fill('Using \"mv\" for moving something from one project to another is unsupported.  Use \"cp\" and \"rm\".') + '\n')

        if src_result is None:
            src_folders.append(src_folderpath)
        else:
            src_objects.append(src_result['id'])
    try:
        dxpy.DXHTTPRequest('/' + src_proj + '/move',
                           {"objects": src_objects,
                            "folders": src_folders,
                            "destination": dest_path})
    except BaseException as details:
        parser.exit(1, fill(str(details)) + '\n')

# ONLY for between DIFFERENT projects.  Will exit fatally otherwise.
def cp(args):
    try:
        dest_proj, dest_path, none = resolve_path_with_project(args.destination, 'folder')
        dx_dest = dxpy.get_handler(dest_proj)
        dx_dest.list_folder(folder=dest_path, only='folders')
    except:
        # Destination folder path is new => renaming
        if len(args.sources) != 1:
            # Can't rename more than one object
            parser.exit(1, 'The destination folder does not exist\n')
        last_slash_pos = get_last_pos_of_char('/', dest_path)
        if last_slash_pos == 0:
            dest_folder = '/'
        else:
            dest_folder = dest_path[:last_slash_pos]
        dest_name = dest_path[last_slash_pos + 1:].replace('\/', '/')
        try:
            dx_dest.list_folder(folder=dest_folder, only='folders')
        except:
            parser.exit(1, 'The destination folder does not exist\n')

        # Clone and rename either the data object or the folder
        # src_result is None if it could not be resolved to an object
        src_proj, src_path, src_result = resolve_existing_path(args.sources[0])

        if src_proj == dest_proj:
            parser.exit(1, fill('Using \"cp\" for copying something to a destination inside the same project is unsupported.') + '\n')

        if src_result is None:
            contents = dxpy.DXHTTPRequest('/' + src_proj + '/listFolder',
                                          {"folder": src_path,
                                           "includeHidden": True})
            dxpy.DXHTTPRequest('/' + dest_proj + '/newFolder',
                               {"folder": dest_path})
            dxpy.DXHTTPRequest('/' + src_proj + '/clone',
                               {"folders": [contents['folders']],
                                "objects": (lambda result: result['id'], contents),
                                "project": dest_proj,
                                "destination": dest_path})
            return
        else:
            try:
                dxpy.DXHTTPRequest('/' + src_proj + '/clone',
                                   {"objects": [src_result['id']],
                                    "project": dest_proj,
                                    "destination": dest_folder})
                dxpy.DXHTTPRequest('/' + src_result['id'] + '/rename',
                                   {"project": dest_proj,
                                    "name": dest_name})
                return
            except BaseException as details:
                parser.exit(1, fill(str(details)) + '\n')

    src_objects = []
    src_folders = []
    for source in args.sources:
        src_proj, src_folderpath, src_result = resolve_existing_path(source)
        if src_proj == dest_proj:
            parser.exit(1, fill('Using \"cp\" for copying something to a destination inside the same project is unsupported.') + '\n')

        if src_result is None:
            src_folders.append(src_folderpath)
        else:
            src_objects.append(src_result['id'])
    try:
        dxpy.DXHTTPRequest('/' + src_proj + '/clone',
                           {"objects": src_objects,
                            "folders": src_folders,
                            "project": dest_proj,
                            "destination": dest_path})
    except BaseException as details:
        parser.exit(1, fill(str(details)) + '\n')

def get_io_desc(parameter, include_class=True, show_opt=True):
    desc = ""
    is_optional = False;
    if show_opt:
        if "default" in parameter or ("optional" in parameter and parameter["optional"]):
            is_optional = True
            desc += "["
    desc += parameter["name"]
    include_parens = include_class or 'type' in parameter or 'default' in parameter
    if include_parens:
        desc += " ("
    is_first = True
    if include_class:
        desc += parameter["class"]
        is_first = False
    if "type" in parameter:
        if not is_first:
            desc += ", "
        else:
            is_first = False
        if isinstance(parameter["type"], dict):
            desc += "type satisfying " + json.dumps(parameter["type"])
        else:
            desc += "type " + parameter["type"]
    if "default" in parameter:
        if not is_first:
            desc += ', '
        desc += json.dumps(parameter['default'])
    if include_parens:
        desc += ")"
    if show_opt and is_optional:
        desc += "]"
    return desc

def get_io_spec(spec):
    return '\n\t\t'.join(map(get_io_desc, spec))

def print_project_desc(desc):
    recognized_fields = ['id', 'class', 'name', 'description', 'owner', 'protected', 'restricted', 'created', 'modified', 'dataUsage', 'tags', 'level', 'folders', 'objects', 'permissions', 'appWorkspaces']

    print "ID\t\t" + desc["id"]
    print "Class\t\t" + desc["class"]
    if "name" in desc:
        print "Name\t\t" + desc["name"]
    if 'description' in desc:
        print fill("Description\t" + desc["description"], subsequent_indent='\t\t', width=64)
    print "Owner\t\t" + desc["owner"]
    if 'protected' in desc:
        print "Protected\t" + json.dumps(desc["protected"])
    if 'restricted' in desc:
        print "Restricted\t" + json.dumps(desc["restricted"])
    print "Created\t\t" + datetime.datetime.fromtimestamp(desc['created']/1000).ctime()
    print "Last modified\t" + datetime.datetime.fromtimestamp(desc['modified']/1000).ctime()
    print "Data usage\t" + str(desc["dataUsage"])
    if 'tags' in desc:
        print "Tags\t\t" + json.dumps(desc["tags"])
    if "level" in desc:
        print "Access level\t" + desc["level"]
    if "folders" in desc:
        print "Folders\t\t" + ', '.join(desc["folders"])
    if "objects" in desc:
        print "# Files\t\t" + str(desc["objects"])
    if "permissions" in desc:
        print "Permissions\t" + json.dumps(desc["permissions"])
    if "appWorkspaces" in desc:
        print "App workspaces\t" + json.dumps(desc["appWorkspaces"])

    for field in desc:
        if field not in recognized_fields:
            print field + '\t\t' + json.dumps(desc[field])

def print_app_desc(desc):
    recognized_fields = ['id', 'class', 'owner', 'name', 'version', 'aliases', 'createdBy', 'created', 'modified', 'program', 'deleted', 'published', 'title', 'subtitle', 'description', 'categories', 'access', 'dxapi', 'inputSpec', 'outputSpec', 'runSpec', 'globalWorkspace', 'installed', 'openSource', 'inputs', 'outputs', 'run', 'summary']

    print "ID\t\t" + desc["id"]
    print "Class\t\t" + desc["class"]
    print "Owner\t\t" + desc["owner"]
    print "Name\t\t" + desc["name"]
    print "Version\t\t" + desc["version"]
    print "Aliases\t\t" + ', '.join(desc["aliases"])
    print "Created by\t" + desc["createdBy"]
    print "Created\t\t" + datetime.datetime.fromtimestamp(desc['created']/1000).ctime()
    print "Last modified\t" + datetime.datetime.fromtimestamp(desc['modified']/1000).ctime()
    if "program" in desc:
        print "Created from\t" + desc["program"]
    if desc['installed'] == True:
        print 'Installed\ttrue'
    else:
        print 'Installed\tfalse'
    if desc['openSource'] == True:
        print 'Open source\ttrue'
    else:
        print 'Open source\tfalse'
    if desc["deleted"]:
        print "Deleted\t\ttrue"
    else:
        print "Deleted\t\tfalse"

        if 'published' not in desc or desc["published"] < 0:
            "Published\tN/A"
        else:
            "Published\t" + datetime.datetime.fromtimestamp(desc['published']/1000).ctime()

    if not desc["deleted"]:
        if "title" in desc:
            print "Title\t\t" + desc["title"]
        if "subtitle" in desc:
            print "Subtitle\t\t" + desc["subtitle"]
        if 'summary' in desc:
            print fill("Summary\t\t" + desc['summary'], subsequent_indent='\t\t', width=64)
        if "description" in desc:
            print fill("Description\t" + desc["description"], subsequent_indent='\t\t', width=64)
        print "Categories\t" + ', '.join(desc["categories"])
        print "Access\t\t" + json.dumps(desc["access"])
        print "API version\t" + desc["dxapi"]
        if 'inputSpec' in desc:
            print "Input Spec\t" + get_io_spec(desc["inputSpec"])
            print "Output Spec\t" + get_io_spec(desc["outputSpec"])
            print "Interpreter\t" + desc["runSpec"]["interpreter"]
            if "resources" in desc["runSpec"]:
                print "Resources\t" + json.dumps(desc["runSpec"]["resources"])
            if "bundledDepends" in desc["runSpec"]:
                print "bundledDepends\t" + fill(json.dumps(desc["runSpec"]["bundledDepends"]), width=64, subsequent_indent='\t\t')
            if "execDepends" in desc["runSpec"]:
                print "execDepends\t" + json.dumps(desc["runSpec"]["execDepends"])
        elif 'inputs' in desc:
            print "Input Spec\t" + get_io_spec(desc['inputs'])
            print "Output Spec\t" + get_io_spec(desc['outputs'])
            print "Interpreter\t" + desc["run"]["interpreter"]
            if "resources" in desc["run"]:
                print "Resources\t" + json.dumps(desc["runSpec"]["resources"])
            if "bundledDepends" in desc["run"]:
                print "bundledDepends\t" + fill(json.dumps(desc["run"]["bundledDepends"]), width=64, subsequent_indent='\t\t')
            if "execDepends" in desc["run"]:
                print "execDepends\t" + json.dumps(desc["run"]["execDepends"])
        print "GlobalWorkspace\t" + desc["globalWorkspace"]

    for field in desc:
        if field not in recognized_fields:
            print field + '\t\t' + json.dumps(desc[field])

def print_data_obj_desc(desc):
    recognized_fields = ['id', 'class', 'project', 'folder', 'name', 'properties', 'tags', 'types', 'hidden', 'details', 'links', 'created', 'modified', 'state', 'title', 'subtitle', 'description', 'inputSpec', 'outputSpec', 'runSpec', 'summary', 'dxapi', 'access', 'createdBy', 'summary']
    print "ID\t\t" + desc["id"]
    print "Class\t\t" + desc["class"]
    if 'project' in desc:
        print "Project\t\t" + desc["project"]
    if 'folder' in desc:
        print "Folder\t\t" + desc["folder"]
    print "Name\t\t" + desc["name"]
    if 'state' in desc:
        if desc['state'] in DATA_STATES:
            print "State\t\t" + DATA_STATES[desc['state']]
        else:
            print "State\t\t" + desc["state"]
    if 'hidden' in desc:
        print "Hidden\t\t" + json.dumps(desc["hidden"])
    if 'types' in desc:
        print "Types\t\t" + json.dumps(desc["types"])
    if 'properties' in desc:
        print "Properties\t" + json.dumps(desc["properties"])
    if 'tags' in desc:
        print "Tags\t\t" + json.dumps(desc["tags"])
    if 'details' in desc:
        print "Details\t\t" + json.dumps(desc["details"])
    if 'links' in desc:
        print "Outgoing links\t" + json.dumps(desc["links"])
    print "Created\t\t" + datetime.datetime.fromtimestamp(desc['created']/1000).ctime()
    if 'createdBy' in desc:
        print "Created by\t" + desc['createdBy']['user']
    print "Last modified\t" + datetime.datetime.fromtimestamp(desc['modified']/1000).ctime()
    if "title" in desc:
        print "Title\t\t" + desc["title"]
    if "subtitle" in desc:
        print "Subtitle\t\t" + desc["subtitle"]
    if 'summary' in desc:
        print fill("Summary\t\t" + desc['summary'], subsequent_indent='\t\t', width=64)
    if "description" in desc:
        print fill("Description\t" + desc["description"], subsequent_indent='\t\t', width=64)
    if 'summary' in desc:
        print fill('Summary\t\t' + desc['summary'], subsequent_indent='\t\t', width=64)
    if 'access' in desc:
        print "Access\t\t" + json.dumps(desc["access"])
    if 'dxapi' in desc:
        print "API version\t" + desc["dxapi"]
    if "inputSpec" in desc:
        print "Input Spec\t" + get_io_spec(desc['inputSpec'])
    if "outputSpec" in desc:
        print "Output Spec\t" + get_io_spec(desc['outputSpec'])
    if 'runSpec' in desc:
        print "Interpreter\t" + desc["runSpec"]["interpreter"]
        if "resources" in desc['runSpec']:
            print "Resources\t" + json.dumps(desc["runSpec"]["resources"])
        if "bundledDepends" in desc['runSpec']:
            print "bundledDepends\t" + fill(json.dumps(desc["runSpec"]["bundledDepends"]), width=64, subsequent_indent='\t\t')
        if "execDepends" in desc['runSpec']:
            print "execDepends\t" + json.dumps(desc["runSpec"]["execDepends"])

    for field in desc:
        if field in recognized_fields:
            continue
        else:
            if field == "media":
                print "Media type\t" + desc['media']
            elif field == "size":
                if desc["class"] == "file" or desc["class"] == "gtable":
                    print "Size (bytes)\t" + str(desc['size'])
                else:
                    print "Size\t\t" + str(desc['size'])
            elif field == "length":
                if desc["class"] == "gtable":
                    print "Size (rows)\t" + str(desc['length'])
                else:
                    print "Size\t\t" + str(desc['length'])
            elif field == "columns":
                coldescs = ""
                for column in desc["columns"]:
                    coldescs += "\t\t" + column["name"] + " (" + column["type"] + ")\n"
                print "Columns" + coldescs[:-1]
            else: # Unhandled prettifying
                print field + "\t\t" + json.dumps(desc[field])

def print_job_desc(desc):
    recognized_fields = ['id', 'class', 'project', 'workspace', 'program', 'app', 'state', 'parentJob', 'originJob', 'function', 'originalInput', 'input', 'output', 'folder', 'launchedBy', 'created', 'modified', 'failureReason', 'failureMessage', 'stdout', 'stderr', 'waitingOnChildren', 'projectWorkspace', 'globalWorkspace']

    print "ID\t\t" + desc["id"]
    print "Class\t\t" + desc["class"]
    print "Project context\t" + desc["project"]
    print "Workspace\t" + desc["workspace"]
    if 'projectWorkspace' in desc:
        print 'Cache workspace\t' + desc['projectWorkspace']
        print 'GlobalWorkspace\t' + desc['globalWorkspace']
    if "program" in desc:
        print "Program\t\t" + desc["program"]
    elif "app" in desc:
        print "App\t\t" + desc["app"]
    if desc['state'] in JOB_STATES:
        print "State\t\t" + JOB_STATES[desc["state"]]
    else:
        print "State\t\t" + desc['state']
    if desc["parentJob"] is None:
        print "Parent job\tNone"
    else:
        print "Parent job\t" + json.dumps(desc["parentJob"])
    print "Origin job\t" + desc["originJob"]
    print "Function\t" + desc["function"]
    if "originalInput" in desc:
        print "Original Input\t" + json.dumps(desc["originalInput"])
        print "Input\t\t" + json.dumps(desc["input"])
        print "Output\t\t" + json.dumps(desc["output"])
    if 'folder' in desc:
        print 'Output folder\t' + desc['folder']
    print "Launched by\t" + desc["launchedBy"]
    print "Created\t\t" + datetime.datetime.fromtimestamp(desc['created']/1000).ctime()
    print "Last modified\t" + datetime.datetime.fromtimestamp(desc['modified']/1000).ctime()
    if 'waitingOnChildren' in desc:
        if len(desc['waitingOnChildren']) == 0:
            print 'Pending subjobs\tNone'
        else:
            print 'Pending subjobs\t' + ', '.join(desc['waitingOnChildren'])
    if "failureReason" in desc:
        print "Failure reason\t" + desc["failureReason"]
    if "failureMessage" in desc:
        print fill("Failure message\t" + desc["failureMessage"], subsequent_indent='\t\t', width=64)
    if "stdout" in desc:
        print "File of stdout\t" + str(desc['stdout'])
    if 'stderr' in desc:
        print 'File of stderr\t' + str(desc['stderr'])
    for field in desc:
        if field not in recognized_fields:
            print field + '\t\t' + json.dumps(desc[field])

def print_desc(desc):
    if desc['class'] in ['project', 'workspace', 'container']:
        print_project_desc(desc)
    elif desc['class'] == 'app':
        print_app_desc(desc)
    elif desc['class'] == 'job':
        print_job_desc(desc)
    else:
        print_data_obj_desc(desc)

def describe(args):
    # Attempt to resolve name
    # First, if it looks like a hash id, do that.
    json_input = {}
    if args.properties:
        json_input["properties"] = True
    if args.details:
        json_input["details"] = True
    if is_data_obj_id(args.path):
        # Should prefer the current project's version if possible
        if 'DX_PROJECT_CONTEXT_ID' in os.environ:
            json_input['project'] = os.environ['DX_PROJECT_CONTEXT_ID']

    # Otherwise, attempt to look for it as a data object.
    project, folderpath, entity_results = resolve_existing_path(args.path, expected='entity', only_one=False)

    found_match = False

    get_result_str = ResultCounter()

    # Could be a project
    if entity_results is None:
        if args.path[-1] == ':':
            # It is the project.
            try:
                desc = dxpy.DXHTTPRequest('/' + project + '/describe', json_input)
                found_match = True
                print get_result_str()
                print_desc(desc)
            except:
                pass
        elif is_container_id(args.path):
            try:
                desc = dxpy.DXHTTPRequest('/' + args.path + '/describe', json_input)
                found_match = True
                print get_result_str()
                print_desc(desc)
            except:
                pass

    # Found data object or is an id
    if entity_results is not None:
        if len(entity_results) > 0:
            found_match = True
        for result in entity_results:
            print get_result_str()
            print_desc(result['describe'])

    if not is_hashid(args.path):

        # Could be an app name
        if args.path.startswith('app-'):
            try:
                desc = dxpy.DXHTTPRequest('/' + args.path + '/describe', {})
                print get_result_str()
                print_desc(desc)
                found_match = True
            except:
                pass
        else:
            for result in dxpy.find_apps(name=args.path, describe=True):
                print get_result_str()
                print_desc(result['describe'])
                found_match = True

        # Could be a user
        if args.path.startswith('user'):
            try:
                desc = dxpy.DXHTTPRequest('/' + args.path + '/describe', {"appsInstalled": True, "subscriptions": True})
                found_match = True

                print get_result_str()

                print "ID\t\t" + desc["id"]
                print "Name\t\t" + desc["first"] + " " + ((desc["middle"] + " ") if desc["middle"] != '' else '') + desc["last"]
                if "email" in desc:
                    print "Email\t\t" + desc["email"]
                if "appsInstalled" in desc:
                    if len(desc["appsInstalled"]) == 0:
                        print "Apps installed\tNone"
                    else:
                        print "Apps installed\t" + fill(', '.join(desc["appsInstalled"].keys()), width=64, subsequent_indent='\t\t')
            except dxpy.DXAPIError as details:
                pass

        # Could be an org or team
        if args.path.startswith('org-') or args.path.startswith('team-'):
            try:
                desc = dxpy.DXHTTPRequest('/' + args.path + '/describe', {})
                found_match = True
                print get_result_str()
                for field in desc:
                    print field + '\t\t' + json.dumps(desc[field])
            except dxpy.DXAPIError as details:
                pass

    if not found_match:
        print "No matches found for " + args.path

def get_properties_from_args(args_properties):
    properties = None
    if args_properties is not None:
        if len(args_properties) % 2 != 0:
            raise SyntaxError('Even number of key/value strings expected for --properties')
        properties = {}
        for i in range(len(args_properties)/2):
            properties[ args_properties[2*i] ] = args_properties[2*i+1]
    return properties

def new_project(args):
    try:
        resp = dxpy.DXHTTPRequest('/project/new',
                                  {"name": args.name})
        print fill('Created new project called \"' + args.name + '\" (' + resp['id'] + ')')
    except BaseException as details:
        parser.exit(1, fill(str(details)) + '\n')

def new_record(args):
    hidden = (args.visibility == 'hidden')
    properties = get_properties_from_args(args.properties)
    details = None
    if args.details is not None:
        try:
            details = json.loads(args.details)
        except:
            parser.exit(1, 'Error: details could not be parsed as JSON\n')
    init_from = None
    if args.init is not None:
        init_from = dxpy.DXRecord(args.init)

    dxrecord = None
    try:
        dxrecord = dxpy.new_dxrecord(project=args.project, name=args.name,
                                     tags=args.tags, types=args.types, 
                                     hidden=hidden, properties=properties,
                                     details=details,
                                     folder=args.folder,
                                     parents=args.parents, init_from=init_from)
        print dxrecord.get_id()
    except dxpy.DXAPIError as details:
        parser.exit(1, fill(str(details)) + '\n')

def new_gtable(args):
    hidden = (args.visibility == 'hidden')
    properties = get_properties_from_args(args.properties)
    details = None
    if args.details is not None:
        try:
            details = json.loads(args.details)
        except:
            parser.exit(1, 'Error: details could not be parsed as JSON\n')

    json_input = {}
    if args.input is not None:
        with open(args.input, 'r') as fd:
            data = fd.read()
            json_input = json.loads(data)

    if 'columns' in json_input:
        args.columns = json_input['columns']
    elif args.columns is not None:
        args.columns = json.loads(args.columns)
    if 'indices' in json_input:
        args.indices = json_input['indices']
    elif args.indices is not None:
        args.indices = json.loads(args.indices)

    try:
        dxgtable = dxpy.new_dxgtable(project=args.project, name=args.name,
                                     tags=args.tags, types=args.types, 
                                     hidden=hidden, properties=properties,
                                     details=details,
                                     folder=args.folder,
                                     parents=args.parents,
                                     columns=args.columns,
                                     indices=args.indices)
        print dxgtable.get_id()
    except dxpy.DXAPIError as details:
        parser.exit(1, fill(str(details)) + '\n')

def set_visibility(args):
    # Attempt to resolve name
    project, folderpath, entity_result = resolve_existing_path(args.path, expected='entity')

    if entity_result is None:
        parser.exit(1, fill('Could not resolve \"' + args.path + '\" to a name or ID'), + '\n')

    try:
        dxpy.DXHTTPRequest('/' + entity_result['id'] + '/setVisibility',
                           {"hidden": (args.visibility == 'hidden')})
    except dxpy.DXAPIError as details:
        parser.exit(1, fill(str(details)) + '\n')

def get_details(args):
    # Attempt to resolve name
    project, folderpath, entity_result = resolve_existing_path(args.path, expected='entity')

    if entity_result is None:
        parser.exit(1, fill('Could not resolve \"' + args.path + '\" to a name or ID') + '\n')

    try:
        print json.dumps(dxpy.DXHTTPRequest('/' + entity_result['id'] + '/getDetails', {}), indent=4)
    except dxpy.DXAPIError as details:
        parser.exit(1, fill(str(details)) + '\n')

def set_details(args):
    # Attempt to resolve name
    project, folderpath, entity_result = resolve_existing_path(args.path, expected='entity')

    if entity_result is None:
        parser.exit(1, fill('Could not resolve \"' + args.path + '\" to a name or ID') + '\n')

    try:
        args.details = json.loads(args.details)
        dxpy.DXHTTPRequest('/' + entity_result['id'] + '/setDetails',
                           args.details)
    except ValueError:
        print 'Error: details could not be parsed as JSON'
    except dxpy.DXAPIError as details:
        parser.exit(1, fill(str(details)) + '\n')

def add_types(args):
    # Attempt to resolve name
    project, folderpath, entity_result = resolve_existing_path(args.path, expected='entity')

    if entity_result is None:
        parser.exit(1, fill('Could not resolve \"' + args.path + '\" to a name or ID') + '\n')

    try:
        dxpy.DXHTTPRequest('/' + entity_result['id'] + '/addTypes',
                           {"types": args.types})
    except dxpy.DXAPIError as details:
        parser.exit(1, fill(str(details)) + '\n')

def remove_types(args):
    # Attempt to resolve name
    project, folderpath, entity_result = resolve_existing_path(args.path, expected='entity')

    if entity_result is None:
        parser.exit(1, fill('Could not resolve \"' + args.path + '\" to a name or ID') + '\n')

    try:
        dxpy.DXHTTPRequest('/' + entity_result['id'] + '/removeTypes',
                           {"types": args.types})
    except dxpy.DXAPIError as details:
        parser.exit(1, fill(str(details)) + '\n')

def add_tags(args):
    # Attempt to resolve name
    project, folderpath, entity_result = resolve_existing_path(args.path, expected='entity')

    if entity_result is None and project is None:
        parser.exit(1, fill('Could not resolve \"' + args.path + '\" to a name or ID') + '\n')

    try:
        if entity_result is not None:
            dxpy.DXHTTPRequest('/' + entity_result['id'] + '/addTags',
                               {"project": project,
                                "tags": args.tags})
        elif not project.startswith('project-'):
            raise TypeError ('Cannot add tags to a non-project data container\n')
        else:
            dxpy.DXHTTPRequest('/' + project + '/addTags',
                               {"tags": args.tags})
    except dxpy.DXAPIError as details:
        parser.exit(1, fill(str(details)) + '\n')

def remove_tags(args):
    # Attempt to resolve name
    project, folderpath, entity_result = resolve_existing_path(args.path, expected='entity')

    if entity_result is None and project is None:
        parser.exit(1, 'Could not resolve \"' + args.path + '\" to a name or ID\n')

    try:
        if entity_result is not None:
            dxpy.DXHTTPRequest('/' + entity_result['id'] + '/removeTags',
                               {"project": project,
                                "tags": args.tags})
        elif not project.startswith('project-'):
            raise TypeError ('Cannot remove tags from a non-project data container\n')
        else:
            dxpy.DXHTTPRequest('/' + project + '/removeTags',
                               {"tags": args.tags})
    except dxpy.DXAPIError as details:
        parser.exit(1, fill(str(details)) + '\n')

def rename(args):
    # Attempt to resolve name
    project, folderpath, entity_result = resolve_existing_path(args.path, expected='entity')

    if entity_result is None and not is_container_id(args.path):
        if project is None:
            parser.exit(1, 'Could not resolve \"' + args.path + '\" to a name or ID\n')
        elif folderpath != None and folderpath != '/':
            parser.exit(1,
                        'Could not resolve \"' + args.path + \
                            '''\" to an existing data object or folder; if you
were attempting to refer to a project, append a colon ":" to indicate that it
is a project.\n''')

    try:
        if entity_result is not None:
            dxpy.DXHTTPRequest('/' + entity_result['id'] + '/rename',
                               {"project": project,
                                "name": args.name})
        elif not project.startswith('project-'):
            raise TypeError ('Cannot rename a non-project data container\n')
        else:
            dxpy.DXHTTPRequest('/' + project + '/update',
                               {"name": args.name})
    except dxpy.DXAPIError as details:
        parser.exit(1, fill(str(details)) + '\n')

def set_properties(args):
    # Attempt to resolve name
    project, folderpath, entity_result = resolve_existing_path(args.path, expected='entity')

    if entity_result is None and project is None:
        parser.exit(1, 'Could not resolve \"' + args.path + '\" to a name or ID\n')

    properties = get_properties_from_args(args.properties)
    try:
        if entity_result is not None:
            dxpy.DXHTTPRequest('/' + entity_result['id'] + '/setProperties',
                               {"project": project,
                                "properties": properties})
        elif not project.startswith('project-'):
            raise TypeError ('Cannot set properties on a non-project data container\n')
        else:
            dxpy.DXHTTPRequest('/' + project + '/setProperties',
                               {"properties": properties})
        dxpy.get_handler(entity_result['id']).set_properties(properties)
    except dxpy.DXAPIError as details:
        parser.exit(1, fill(str(details)) + '\n')

def unset_properties(args):
    # Attempt to resolve name
    project, folderpath, entity_result = resolve_existing_path(args.path, expected='entity')

    if entity_result is None and project is None:
        parser.exit(1, 'Could not resolve \"' + args.path + '\" to a name or ID\n')

    properties = {}
    for prop in args.properties:
        properties[prop] = None
    try:
        if entity_result is not None:
            dxpy.DXHTTPRequest('/' + entity_result['id'] + '/setProperties',
                               {"project": project,
                                "properties": properties})
        elif not project.startswith('project-'):
            raise TypeError ('Cannot unset properties on a non-project data container\n')
        else:
            dxpy.DXHTTPRequest('/' + project + '/setProperties',
                               {"properties": properties})
        dxpy.get_handler(entity_result['id']).set_properties(properties)
    except dxpy.DXAPIError as details:
        parser.exit(1, fill(str(details)) + '\n')

def head(args):
    # Attempt to resolve name
    project, folderpath, entity_result = resolve_existing_path(args.path, expected='entity')
    if not entity_result['describe']['class'] in ['gtable', 'file', 'table']:
        parser.exit(1, 'Error: The given object is of class ' + entity_result['describe']['class'] + ' but an object of class gtable, file, or table was expected\n')

    handler = dxpy.get_handler(entity_result['id'])

    counter = 0
    if args.lines > 0:
        try:
            if handler._class == 'file':
                handler._bufsize = 1024*32;
                for line in handler:
                    print line
                    counter += 1
                    if counter == args.lines:
                        break
            else:
                for line in handler.iterate_rows(end=args.lines):
                    print BOLD + BLUE + str(line[0]) + ': ' + ENDC + json.dumps(line[1:])
                    counter += 1
                    if counter == args.lines:
                        break
        except StopIteration:
            pass
        except BaseException as details:
            parser.exit(1, fill(str(details)) + '\n')

def file_get(args):
    # Attempt to resolve name
    project, folderpath, entity_result = resolve_existing_path(args.path, expected='entity')

    if entity_result is None or entity_result['describe']['class'] != 'file':
        parser.exit(1, 'Could not resolve \"' + args.path + '\" to a file object\n')

    if args.stdout:
        try:
            dxfile = dxpy.DXFile(entity_result['id'])
            for line in dxfile:
                print line
        except dxpy.DXAPIError as details:
            parser.exit(1, fill(str(details)) + '\n')
    else:
        filename = args.output
        if filename is None:
            filename = urllib.quote(entity_result['describe']['name'], safe='')
        try:
            dxpy.download_dxfile(entity_result['id'], filename)
        except dxpy.DXAPIError as details:
            parser.exit(1, fill(str(details)) + '\n')

def upload(args):
    hidden = (args.visibility == 'hidden')
    properties = get_properties_from_args(args.properties)
    details = None
    if args.details is not None:
        try:
            details = json.loads(args.details)
        except:
            parser.exit(1, 'Error: details could not be parsed as JSON\n')
    if args.name is None:
        args.name = os.path.basename(args.filename)

    try:
        dxfile = dxpy.upload_local_file(args.filename,
                                        name=args.name,
                                        tags=args.tags,
                                        types=args.types,
                                        hidden=hidden,
                                        project=args.project,
                                        properties=properties,
                                        details=details,
                                        folder=args.folder,
                                        parents=args.parents)
        if args.wait:
            dxfile._wait_on_close()
        if args.id_only:
            print dxfile.get_id()
        else:
            print_desc(dxfile.describe(incl_properties=True, incl_details=True))
    except BaseException as details:
        parser.exit(1, fill(str(details)) + '\n')

def gtable_get(args):
    # Attempt to resolve name
    project, folderpath, entity_result = resolve_existing_path(args.path, expected='entity')

    if entity_result is None or entity_result['describe']['class'] != 'gtable':
        parser.exit(1, 'Could not resolve \"' + args.path + '\" to a gtable object\n')

    gri_query = None
    if args.gri is not None:
        gri_query = dxpy.DXGTable.genomic_range_query(args.gri[0],
                                                      int(args.gri[1]),
                                                      int(args.gri[2]),
                                                      args.gri_mode,
                                                      args.gri_name)
    try:
        result = dxpy.DXGTable(entity_result['id']).get_rows(query=gri_query,
                                                             starting=args.starting,
                                                             limit=args.limit)
        if args.json:
            print json.dumps(result, indent=4)
            return
        if result["next"] is not None:
            print "Use as STARTING to continue query: " + str(result["next"])
        print "# retrieved rows: " + str(result["length"])
        for row in result["data"]:
            print json.dumps(row, indent=4)
    except dxpy.DXAPIError as details:
        parser.exit(1, fill(str(details)) + '\n')

def find_jobs(args):
    try:
        describe = args.nodesc
        if args.nodesc is True:
            describe = {"io": False}
        results = list(dxpy.find_jobs(launched_by=args.user, program=args.program, project=args.project,
                                      state=args.state, origin_job=args.origin, parent_job=args.parent,
                                      describe=describe,
                                      created_after=args.created_after, created_before=args.created_before))

        if args.json:
            print json.dumps(results, indent=4)
            return
        if not args.nodesc:
            for result in results:
                print result["id"]
        else:
            job_ids = {}
            job_children = {}
            origin_jobs = []
            for i in range(len(results)):
                job_ids[results[i]['id']] = i
                parent = results[i]['describe']['parentJob']
                if parent is None:
                    origin_jobs.append(i)
                elif parent in job_children:
                    job_children[parent].append(i)
                else:
                    job_children[parent] = [i]

            def print_children(parent_id, num_tabs):
                print_string = ""
                for j in range(num_tabs):
                    print_string += '\t'
                print_string += parent_id + ' ' + \
                    str(datetime.datetime.fromtimestamp(results[job_ids[parent_id]]['describe']['created']/1000)) + \
                    ' ('
                state = results[ job_ids[parent_id] ]['describe']['state']
                if state in JOB_STATES:
                    print_string += JOB_STATES[state]
                else:
                    print_string += state
                print_string += ')'
                print print_string

                if parent_id in job_children:
                    for child in job_children[parent_id]:
                        print_children(results[child]['id'], num_tabs + 1)

            for origin_job in origin_jobs:
                orig_id = results[origin_job]["id"]
                print_children(orig_id, 0)
    except dxpy.DXAPIError as details:
        parser.exit(1, fill(str(details)) + '\n')

def find_data(args):
    properties = get_properties_from_args(args.properties)
    try:
        results = list(dxpy.find_data_objects(classname=args.classname, state=args.state,
                                              visibility=args.visibility, properties=properties,
                                              name=args.name,
                                              typename=args.type, tag=args.tag, link=args.link,
                                              project=args.project, folder=args.folder,
                                              recurse=args.recurse,
                                              modified_after=args.mod_after, modified_before=args.mod_before,
                                              created_after=args.created_after, created_before=args.created_before,
                                              describe=args.describe))
        if args.json:
            print json.dumps(results, indent=4)
            return
        for result in results:
            if args.describe is True:
                print ""
                print_data_obj_desc(result["describe"])
            else:
                print result["id"]
        print ""
    except dxpy.DXAPIError as details:
        parser.exit(1, fill(str(details)) + '\n')

def find_projects(args):
    try:
        results = list(dxpy.find_projects(name=args.name, level=args.level, describe=True))
        if args.json:
            print json.dumps(results, indent=4)
            return
        for result in results:
            cached_project_names[result['describe']['name']] = result['id']
            print result["id"] + " : " + result['describe']['name'] + ' (' + result["level"] + ')'
        print ""
        return map(lambda result: result["id"], results)
    except dxpy.DXAPIError as details:
        parser.exit(1, fill(str(details)) + '\n')

def find_apps(args):
    try:
        results = list(dxpy.find_apps(name=args.name, category=args.category,
                                      all_versions=args.all,
                                      published=(not args.unpublished),
                                      owner=args.owner, created_by=args.creator,
                                      developer=args.developer,
                                      created_after=args.created_after, created_before=args.created_before,
                                      modified_after=args.mod_after, modified_before=args.mod_before,
                                      describe=True))
                                      
        if args.json:
            print json.dumps(results, indent=4)
            return
        for result in results:
            print result["describe"]["name"] + " (v" + result["describe"]["version"] + ", " + result["id"] + ")"
    except dxpy.DXAPIError as details:
        parser.exit(1, fill(str(details)) + '\n')

def close(args):
    # Attempt to resolve name
    project, folderpath, entity_result = resolve_existing_path(args.path, expected='entity')

    if entity_result is None:
        parser.exit(1, 'Could not resolve \"' + args.path + '\" to a name or ID\n')

    try:
        obj = dxpy.get_handler(entity_result['id'], project=project)
        obj.close()
    except dxpy.DXAPIError as details:
        parser.exit(1, fill(str(details)) + '\n')
    if args.wait:
        obj._wait_on_close()

def build(args):
    parser.exit(1, 'Not yet implemented\n')

def get_exec_inputs(inputs):
    required_inputs = []
    optional_inputs = []
    for input_spec in inputs:
        if "default" in input_spec or ("optional" in input_spec and input_spec["optional"] == True):
            optional_inputs.append(input_spec)
        else:
            required_inputs.append(input_spec)
    return required_inputs, optional_inputs

def parse_bool(string):
    if 'true'.startswith(string.lower()) or string == '1':
        return True
    elif 'false'.startswith(string.lower()) or string == '0':
        return False
    else:
        raise ValueError('Could not resolve \"' + string +  '\" to a boolean')

def parse_obj(string, klass):
    project, path, entity_result = resolve_existing_path(string)
    if entity_result is None:
        raise TypeError('Could not resolve \"' + string + '\" to a name or ID')
    if not entity_result['describe']['class'] == klass:
        raise TypeError('Error: The given object is of class ' + entity_result['describe']['class'] + ' but an object of class ' + klass + ' was expected.')
    return {'$dnanexus_link': entity_result['id']}

parse_input = {'boolean': parse_bool,
               'string': (lambda string: string),
               'float': (lambda string: float(string)),
               'int': (lambda string: int(string)),
               'hash': (lambda string: json.loads(string)),
               'record': (lambda string: parse_obj(string, 'record')),
               'gtable': (lambda string: parse_obj(string, 'gtable')),
               'file': (lambda string: parse_obj(string, 'file')),
               'program': (lambda string: parse_obj(string, 'program')),
               'job': (lambda string: {'$dnanexus_link': string}),
               'app': (lambda string: {'$dnanexus_link': string}),
               'table': (lambda string: parse_obj(string, 'table'))}

def get_input_array(param_desc):
    in_class = param_desc['class'][6:]
    input_array = []
    print '\nEnter list of inputs (^D or empty string to finish) of class ' + BOLD + in_class + ENDC + ' for ' + get_io_desc(param_desc, include_class=False) + ':\n'
    try:
        while True:
            user_input = raw_input(param_desc['name'] + '[' + str(len(input_array)) + "]: ")
            if user_input == '':
                return input_array
            try:
                input_array.append(parse_input[in_class](user_input))
            except ValueError as details:
                print str(details)
                continue
            except TypeError as details:
                print str(details)
                continue
    except KeyboardInterrupt:
        print ''
        print 'Received keyboard interrupt, exiting...'
        parser.exit(0)
    except EOFError:
        return input_array
    except BaseException as details:
        parser.exit(1, fill(str(details)) + '\n')

def get_input_single(param_desc):
    in_class = param_desc['class']
    print '\nEnter input of class ' + BOLD + in_class + ENDC + ' for ' + get_io_desc(param_desc, include_class=False, show_opt=False) +  ':'
    try:
        while True:
            user_input = raw_input(param_desc['name'] + ': ')
            try:
                value = parse_input[in_class](user_input)
            except ValueError as details:
                print str(details)
                continue
            except TypeError as details:
                print str(details)
                continue
            return value
    except KeyboardInterrupt:
        print ''
        print 'Received keyboard interrupt, exiting...'
        parser.exit(0)
    except BaseException as details:
        parser.exit(1, fill(str(details)) + '\n')

def get_input(input_hash, param):
    if param['class'].startswith('array:'):
        input_hash[param['name']] = get_input_array(param)
    else:
        input_hash[param['name']] = get_input_single(param)

def get_optional_inputs(input_hash, optional_inputs):
    names = map(lambda spec: spec['name'], optional_inputs)
    while True:
        print '\nSelect an optional parameter to set by its # (^D or empty string to finish):\n'
        for i in range(len(optional_inputs)):
            opt_str = ' [' + str(i) + '] ' + \
                get_io_desc(optional_inputs[i], show_opt=False)
            if optional_inputs[i]['name'] in input_hash:
                opt_str += ' [=' + GREEN
                opt_str += json.dumps(input_hash[optional_inputs[i]['name']])
                opt_str += ENDC + ']'
            print opt_str
        print ""
        try:
            while True:
                selected = raw_input('Optional param #: ')
                if selected == '':
                    return
                try:
                    opt_num = int(selected)
                    if opt_num < 0 or opt_num >= len(optional_inputs):
                        raise ValueError('Error: Selection is out of range')
                    break
                except ValueError as details:
                    print str(details)
                    continue
            get_input(input_hash, optional_inputs[opt_num])
        except KeyboardInterrupt:
            print ''
            print 'Received keyboard interrupt, exiting...'
            parser.exit(0)
        except EOFError:
            return
        except BaseException as details:
            parser.exit(1, fill(str(details)) + '\n')

def add_input_to_json(inputs, input_json, input_specs):
    '''
    :param inputs: list of [name, value] lists
    :param input_json: input JSON being built
    :param input_specs: list of all input specs
    '''

    if input_specs is not None:
        # Input spec is provided.  Throw errors if name is not found,
        # and respect the "array" class.
        names = map(lambda spec: spec['name'], input_specs)
        found_duplicates = False
        for i in inputs:
            try:
                input_index = names.index(i[0])
            except:
                parser.exit(1, fill('Input field called ' + i[0] + ' was not found in the input spec') + '\n')

            input_class = input_specs[input_index]['class']
            if input_class.startswith('array:'):
                input_class = input_class[6:]
                is_array = True
            else:
                is_array = False

            try:
                parsed = parse_input[input_class](i[1])
            except BaseException as details:
                parser.exit(1, fill(str(details)) + '\n')

            if i[0] not in input_json:
                if is_array:
                    input_json[i[0]] = [parsed]
                else:
                    input_json[i[0]] = parsed
            elif is_array:
                input_json[i[0]].append(parsed)
            else:
                 parser.exit(1, fill('Error: Found duplicate input field names for an input that does not expect an array of inputs') + '\n')

    else:
        # No input spec.  Make them all lists and then un-list them if
        # there's only one element at the end.  (Since arbitrary JSON
        # is valid input.)
        for i in inputs:
            try:
                parsed = json.loads(i[1])
                if i[0] not in input_json:
                    input_json[i[0]] = [parsed]
                else:
                    input_json[i[0]].append(parsed)
            except:
                # Not valid JSON, so resolve it as a name
                project, folderpath, entity_result = resolve_existing_path(i[1], expected='entity')
                if entity_result is None:
                    parser.exit(1, 'Could not resolve ' + i[1] + ' to a value or object ID')
                if i[0] not in input_json:
                    input_json[i[0]] = [{"$dnanexus_link": entity_result['id']}]
                else:
                    input_json[i[0]].append({"$dnanexus_link": entity_result['id']})
        for key in input_json:
            if len(input_json[key]) == 1:
                input_json[key] = input_json[key][0]

def run(args):
    handler = None
    desc = None
    if args.alias is None:
        # Attempt to resolve name
        project, folderpath, entity_results = resolve_existing_path(args.path, expected='entity', only_one=False)
        app_desc = get_app_from_path(args.path)
        if entity_results is not None and len(entity_results) == 1 and app_desc is None:
            handler = dxpy.DXProgram(entity_results[0]['id'])
            desc = entity_results[0]['describe']
        elif entity_results is None and app_desc is not None:
            handler = dxpy.DXApp(dxid=app_desc['id'])
            desc = app_desc
        elif entity_results is not None and app_desc is not None:
            if not sys.stdin.isatty():
                parser.exit(1, 'Found multiple executables with the path ' + args.path + '\n')
            print 'Found multiple executables with the path ' + args.path
            choice = pick(map(lambda result: get_ls_l_desc(result['describe']),
                              entity_results) + ['app-' + app_desc['name'] + ', version ' + app_desc['version']])
            if choice < len(entity_results):
                handler = dxpy.get_handler(entity_results[choice]['id'], project)
                desc = entity_results[choice]['describe']
            else:
                handler = dxpy.DXApp(dxid=app_desc['id'])
                desc = app_desc
        else:
            parser.exit(1, "No matches found for " + args.path + '\n')
    else:
        if args.path.startswith('app-'):
            args.path = args.path[4:]
        handler = dxpy.DXApp(name=args.path, alias=args.alias)
        desc = handler.describe()

    if args.folder is None:
        dest_proj = os.environ.get('DX_PROJECT_CONTEXT_ID', None)
        dest_path = os.environ.get('DX_CLI_WD', '/')
    else:
        dest_proj, dest_path, none = resolve_existing_path(args.folder,
                                                           expected='folder')

    input_json = {}
    if 'inputSpec' in desc:
        required_inputs, optional_inputs = get_exec_inputs(desc["inputSpec"])
    elif 'inputs' in desc:
        required_inputs, optional_inputs = get_exec_inputs(desc["inputs"])
    else:
        required_inputs, optional_inputs = None, None

    if args.input_json is not None:
        try:
            input_json = json.loads(args.input_json)
        except:
            parser.exit(1, 'Error: input could not be parsed as JSON\n')
    elif args.filename is not None:
        try:
            fd = open(args.filename, 'r')
            data = fd.read()
            fd.close()
        except BaseException as details:
            parser.exit(1, fill(str(details)) + '\n')
        try:
            input_json = json.loads(data)
        except:
            parser.exit(1, 'Error: file could not be parsed as JSON\n')
    elif args.stdin:
        try:
            input_json = json.loads(raw_input('Input JSON > '))
        except BaseException as details:
            parser.exit(1, fill(str(details)) + '\n')
    elif args.input is not None:
        input_inputs = []
        try:
            for i in args.input:
                [name, value] = i.split('=')
                input_inputs.append([name, value])
        except:
            parser.exit(1, fill('An input was found that did not conform to the syntax') + '\n -i<input_name>=<input value>\n')
        add_input_to_json(input_inputs, input_json,
                          (required_inputs + optional_inputs) if required_inputs is not None else None)

    elif required_inputs is not None and (len(required_inputs) > 0 or len(optional_inputs) > 0):
        if sys.stdin.isatty():
            print 'No input given.  Entering interactive mode for input selection.'
            try:
                # If running from the command-line (not in the shell),
                # bring up the tab-completer
                import rlcompleter
                readline.parse_and_bind("tab: complete")

                readline.set_completer_delims("")
                # We don't want to assume that the line will start with
                # commands, so make sure the completer is set correctly
                readline.set_completer(DXObjectCompleter())
            except:
                pass

            # Select input interactively
            if len(required_inputs) > 0:
                for param in required_inputs:
                    get_input(input_json, param)
            if len(optional_inputs) > 0:
                get_optional_inputs(input_json, optional_inputs)
            # Reset the completer once we're done grabbing input
            try:
                readline.set_completer(DXCLICompleter())
            except:
                pass
    elif required_inputs is not None:
        if sys.stdin.isatty():        
            print fill('No input given, and program/app takes in no inputs.  Skipping interactive mode for input selection.')
    else:
        if sys.stdin.isatty():
            print fill('No input given, and program has no input specification.  Skipping interactive mode for input selection (no input parameters will be set).  To provide input parameters anyway, please specify them explicitly using one of the input flags.')

    if sys.stdin.isatty():
        print ''
        print 'Using input JSON:'
        print json.dumps(input_json, indent=4)
        print ''

    # Ask for confirmation if a tty and if input was not given as a
    # single JSON.
    if args.input_json is None and args.filename is None and not args.stdin and sys.stdin.isatty():
        try:
            value = raw_input('Confirm running the program/app with this input [Y/n]: ')
        except KeyboardInterrupt:
            print ''
            print 'Received keyboard interrupt, exiting...'
            parser.exit(0)
        except EOFError:
            print ''
            print 'Received ^D, exiting...'
            parser.exit(0)
        except BaseException as details:
            parser.exit(1, fill(str(details)) + '\n')
        if value != '' and not value.lower().startswith('y'):
            parser.exit(0)

    if sys.stdin.isatty():
        print fill("Calling " + handler.get_id() + " with output destination " + dest_proj + ":" + dest_path, subsequent_indent='  ') + '\n'
    try:
        dxjob = handler.run(input_json, project=dest_proj, folder=dest_path)
    except dxpy.DXAPIError as details:
        parser.exit(1, fill(str(details)) + '\n')
    if sys.stdin.isatty():
        print "Job ID: " + dxjob.get_id()
    else:
        print dxjob.get_id()

def kill(args):
    try:
        dxpy.api.jobTerminate(args.jobid)
    except BaseException as details:
        parser.exit(1, fill(str(details)) + '\n')

def shell(orig_args):
    if state['interactive']:
        return
    state['interactive'] = True

    # WARNING: Following two lines may not be platform-independent and
    # should be made so.
    try:
        import rlcompleter
        readline.parse_and_bind("tab: complete")

        readline.set_completer_delims("")

        readline.set_completer(DXCLICompleter())
    except:
        pass

    while True:
        try:
            cmd = raw_input('> ')
        except EOFError:
            print ""
            exit(0)
        except KeyboardInterrupt:
            print ""
            continue
        if cmd == '':
            continue
        try:
            args = parser.parse_args(shlex.split(cmd))
            args.func(args)
        except StopIteration:
            exit(0)
        except BaseException as details:
            if str(details) != '1' and str(details) != '0':
                print str(details) + '\n'

def print_help(args):
    if args.command is None:
        parser.print_help()
    elif args.command not in parser_map:
        parser.exit(1, 'Unrecognized command: ' + args.command + '\n')
    elif args.subcommand is None:
        parser_map[args.command].print_help()
    elif (args.command + ' ' + args.subcommand) not in parser_map:
        parser.exit(1, 'Unrecognized command and subcommand combination: ' + args.command + ' ' + args.subcommand + '\n')
    else:
        parser_map[args.command + ' ' + args.subcommand].print_help()

def exit_shell(args):
    if state['interactive']:
        raise StopIteration()

# TODO: Add a subcommand for clearing the cache

global_args = argparse.ArgumentParser(add_help=False)
global_args.add_argument('--json', help='Display return value in JSON', action='store_true')

parser = argparse.ArgumentParser(epilog='''README: If you have not already set environment variables in your shell to
specify the API server's host and port and/or your default project, use the 'set' subcommand to set these values for
the command-line client.  NOTE: Running 'dxclient login' at the moment will set your variables for using the 'outside'
token.''', description='DNAne' + CYAN + BOLD + 'x' + ENDC + 'us Command-Line Client, API v1.0.0',
usage='dx subcommand [options]')
parser.add_argument('--version', action='version', version='dxclient 0.0.1')

subparsers = parser.add_subparsers()

parser_shell = subparsers.add_parser('sh', help='Run interactive shell', prog='dx sh')
parser_shell.set_defaults(func=shell)
parser_map['sh'] = parser_shell

parser_help = subparsers.add_parser('help', help='Display help message', prog='dx help')
parser_help.add_argument('command', help='Display the help message for the given command', nargs='?', default=None)
parser_help.add_argument('subcommand', help='Display the help message for the given subcommand of the command', nargs='?', default=None)
parser_help.set_defaults(func=print_help)
parser_map['help'] = parser_help

parser_exit = subparsers.add_parser('exit', help='Exit out of the interactive shell', prog='dx exit')
parser_exit.set_defaults(func=exit_shell)
parser_map['exit'] = parser_exit

parser_setenv = subparsers.add_parser('setenv', help='Sets environment variables for communication with the API server',
                                      description='Sets environment variables for communication with the API server')
parser_setenv.add_argument('--noprojects', dest='projects', help='Do not print available projects', action='store_false')
parser_setenv.add_argument('--save', help='Save settings for future sessions.  Only one set of settings can be saved at a time.  Always set to true if login is run in a non-interactive session', action='store_true')
parser_setenv.add_argument('--current', help='Do not prompt for new values and just save current settings for future sessions.  Overrides --save to be true.', action='store_true')
parser_setenv.set_defaults(func=setenv)

parser_clearenv = subparsers.add_parser('clearenv', help='Clears all environment variables set by dx', prog='dx clearenv')
parser_clearenv.set_defaults(func=clearenv)
parser_map['clearenv'] = parser_clearenv

parser_env = subparsers.add_parser('env', help='Prints all environment variables set for the CLI', prog='dx env')
parser_env.add_argument('--bash', help='Prints a list of bash commands to export the environment variables', action='store_true')
parser_env.set_defaults(func=env)
parser_map['env'] = parser_env

parser_login = subparsers.add_parser('login', help='Log in and acquire credentials', description='Log in interactively and acquire credentials', prog='dx login')
parser_login.add_argument('--token', help='Authentication token to use')
parser_login.add_argument('--demo', help='Log into nucleusdemo.dev.dnanexus.com', action='store_true')
parser_login.add_argument('--host', help='Log into the given auth server host (port must also be given)')
parser_login.add_argument('--port', type=int, help='Log into the given auth server port (host must also be given)')
parser_login.add_argument('--noprojects', dest='projects', help='Do not print available projects', action='store_false')
parser_login.add_argument('--save', help='Save token and other environment variables for future sessions', action='store_true')
parser_login.set_defaults(func=login)
parser_map['login'] = parser_login

parser_logout = subparsers.add_parser('logout', help='Log out and remove credentials',
                                      description='Log out and remove credentials',
                                      prog='dx logout')
parser_logout.set_defaults(func=logout)
parser_map['logout'] = parser_logout

parser_select = subparsers.add_parser('select', help='List and select and project to switch to',
                                      prog='dx select')
parser_select.set_defaults(func=pick_and_set_project, save=False)
parser_map['select'] = parser_select

parser_ls = subparsers.add_parser('ls', help='List folders and objects in a folder',
                                  description='List folders and/or objects in a folder',
                                  parents=[global_args], prog='dx ls')
parser_ls.add_argument('-a', '--all', help='show hidden files', action='store_true')
parser_ls.add_argument('-l', help='use a long listing format', action='store_true')
parser_ls.add_argument('--obj', help='show only objects', action='store_true')
parser_ls.add_argument('--folders', help='show only folders', action='store_true')
parser_ls.add_argument('--full', help='show full paths of folders', action='store_true')
parser_ls.add_argument('path', help='Folder (possibly in another project) to list the contents of, default is the current directory in the current project.  Syntax: projectID:/folder/path', nargs='?', default='.')
parser_ls.set_defaults(func=ls)
parser_map['ls'] = parser_ls

parser_cd = subparsers.add_parser('cd', help='Change the current working directory',
                                  description='Change the current working directory', prog='dx cd')
parser_cd.add_argument('path', help='Folder (possibly in another project) to which to change the current working directory, default is \"/\" in the current project', nargs='?', default='/')
parser_cd.set_defaults(func=cd)
parser_map['cd'] = parser_cd

parser_pwd = subparsers.add_parser('pwd', help='Print current working directory',
                                   description='Print current working directory', prog='dx pwd')
parser_pwd.set_defaults(func=pwd)
parser_map['pwd'] = parser_pwd

parser_mkdir = subparsers.add_parser('mkdir', help='Create a new folder',
                                     description='Create a new folder', prog='dx mkdir')
parser_mkdir.add_argument('-p', '--parents', help='no error if existing, create parent directories as needed', action='store_true')
parser_mkdir.add_argument('path', help='Path to a folder to create; full path is required')
parser_mkdir.set_defaults(func=mkdir)
parser_map['mkdir'] = parser_mkdir

parser_rmdir = subparsers.add_parser('rmdir', help='Remove a folder',
                                     description='Remove a folder', prog='dx rmdir')
parser_rmdir.add_argument('path', help='Path to a folder to remove; full path is required')
parser_rmdir.set_defaults(func=rmdir)
parser_map['rmdir'] = parser_rmdir

parser_rm = subparsers.add_parser('rm', help='Remove objects',
                                  description='Remove objects', prog='dx rm')
parser_rm.add_argument('paths', help='Paths to remove', nargs='*')
parser_rm.add_argument('-r', '--recursive', help='Recurse into a directory', action='store_true')
parser_rm.set_defaults(func=rm)
parser_map['rm'] = parser_rm

parser_rmproject = subparsers.add_parser('rmproject', help='Delete projects',
                                         description='Delete projects and all their associated data',
                                         prog='dx rmproject')
parser_rmproject.add_argument('projects', help='Projects to remove', nargs='*')
parser_rmproject.set_defaults(func=rmproject)
parser_map['rmproject'] = parser_rmproject

parser_mv = subparsers.add_parser('mv', help='Move objects and/or folders inside a single project',
                                  description='Move objects and/or folders inside a single project.',
                                  prog='dx mv')
parser_mv.add_argument('sources', help='Objects and/or folder names to move', nargs='*')
parser_mv.add_argument('destination', help='Folder into which to move the sources')
parser_mv.set_defaults(func=mv)
parser_map['mv'] = parser_mv

parser_cp = subparsers.add_parser('cp', help='Copy objects and/or folders between different projects',
                                  description='Copy objects and/or folders between different projects.  Folders will automatically be copied recursively.', prog='dx cp')
parser_cp.add_argument('sources', help='Objects and/or folder names to copy', nargs='*')
parser_cp.add_argument('destination', help='Folder into which to copy the sources')
parser_cp.set_defaults(func=cp)
parser_map['cp'] = parser_cp

parser_head = subparsers.add_parser('head', help='Print the first 10 lines of a file or first 10 rows of a gtable', prog='dx head')
parser_head.add_argument('-n', '--lines', type=int, help='Print the first LINES number of lines or rows', default=10)
parser_head.add_argument('path', help='File or gtable ID or name to access')
parser_head.set_defaults(func=head)
parser_map['head'] = parser_head

parser_cat = subparsers.add_parser('cat', help='Print a file to stdout', prog='dx cat')
parser_cat.add_argument('path', help='File ID or name to print to stdout')
parser_cat.set_defaults(func=file_get, output=None, stdout=True)
parser_map['cat'] = parser_cat

parser_file = subparsers.add_parser('file', help='Interact with remote files', prog='dx file')
subparsers_file = parser_file.add_subparsers()
parser_map['file'] = parser_file

parser_file_get = subparsers_file.add_parser('get', help='Download a file', prog='dx file get')
parser_file_get.add_argument('path', help='File ID or name to download')
parser_file_get.add_argument('--stdout', help='Print the file to stdout', action='store_true')
parser_file_get.add_argument('-o', '--output', help='local filename to be saved; if not supplied, the remote file\'s name or ID will be used')
parser_file_get.set_defaults(func=file_get)
parser_map['file get'] = parser_file_get

parser_gtable = subparsers.add_parser('gtable', help='Interact with remote gtables')
subparsers_gtable = parser_gtable.add_subparsers()
parser_map['gtable'] = parser_gtable

parser_gtable_get = subparsers_gtable.add_parser('get', help='Retrieve rows from a gtable',
                                                 parents=[global_args],
                                                 prog='dx gtable get')
parser_gtable_get.add_argument('--starting', type=int, help='Specify starting row ID (provided by \'next\' if continuing a previous query) for the given query')
parser_gtable_get.add_argument('--limit', type=int, help='Specify a limit to the number of rows returned')
parser_gtable_get.add_argument('--gri', nargs=3, metavar=('CHR', 'LO', 'HI'), help='Specify chromosome name, low coordinate, and high coordinate for Genomic Range Index')
parser_gtable_get.add_argument('--gri-mode', help='Specify the mode of the GRI query (\'overlap\' or \'enclose\'; default \'overlap\')', default="overlap")
parser_gtable_get.add_argument('--gri-name', help='Override the default name of the Genomic Range Index (default: "gri"))', default="gri")
parser_gtable_get.add_argument('path', help='GTable ID from which to fetch rows')
parser_gtable_get.set_defaults(func=gtable_get)
parser_map['gtable get'] = parser_gtable_get

parser_describe = subparsers.add_parser('describe', help='Describe a remote object',
                                        description='Describe a remote object',
                                        parents=[global_args],
                                        prog='dx describe')
parser_describe.add_argument('--project', help='Specify hint for which project to access, default is default project')
parser_describe.add_argument('--properties', help='Include properties', action='store_true')
parser_describe.add_argument('--details', help='Include details if available', action='store_true')
parser_describe.add_argument('path', help='Object ID or path to an object (possibly in another project) to describe.')
parser_describe.set_defaults(func=describe)
parser_map['describe'] = parser_describe

parser_close = subparsers.add_parser('close', help='Close a remote object', description='Close a remote object', prog='dx close')
parser_close.add_argument('path', help='Path to data object to close')
parser_close.add_argument('--wait', help='Wait for the object to close', action='store_true')
parser_close.set_defaults(func=close)
parser_map['close'] = parser_close

parser_build = subparsers.add_parser('build', help='Build an applet/app',
                                     description='Takes in a local directory containing your source code and a dxprogram.json file, and converts it into a program object in the current project.  With the "-a" flag, it can optionally be further packaged into an app object',
                                     prog='dx build')
parser_build.add_argument('directory', help='Path to your local directory')
parser_build.add_argument('-f', '--overwrite', help='Remove existing programs of the same name', action='store_true')
parser_build.add_argument('-a', '--create-app', help='Create an app from the program (requires dxapp.json to be present)', action='store_true')
parser_build.add_argument("-p", "--destination_project", help="Insert the program into the project with the specified project ID.")
parser_build.add_argument('--publish', help='Publish the app after it has been created.', action='store_true')
parser_build.add_argument("-o", "--owner", help="Owner (username or organization) to set for the app.")
parser_build.set_defaults(func=build)
parser_map['build'] = parser_build

parser_run = subparsers.add_parser('run', help='Run a program or app', description=(fill('Run a program or app.  If no inputs are specified, an interactive mode for selecting inputs will be launched.') + '''

SPECIFYING INPUTS

''' + fill('Other than the interactive mode, inputs can be specified by listing each field on the command line, or by giving the entire JSON string (where keys=input field names, values=field values).  Use the empty hash "{}" to signify no inputs.  Inputs cannot be specified by a mix of the different input flags.') + '\n\n  BY NAME\n\n' + fill('To use the "-i" flag to specify each input field name and value, using the syntax "-i<input name>=<input value>".  For example, the following runs the program called "mapper" with 3 inputs called num (class int), str (class string), and gtables (class array:gtable):', initial_indent='  ', subsequent_indent='  ') + '''

    dx run mapper -inum=34 -istr=\'"foo"\' -igtables=reads1 -igtables=reads2

''' + fill('Note that non-name values are parsed as JSON, so strings must be quoted with double quotes.  The same input field can be used multiple times if the input class is an array.', initial_indent='  ', subsequent_indent='  ') + '\n\n  FULL JSON\n\n' + fill('If providing the full input JSON, it can be done using one of the following flags:', initial_indent='  ', subsequent_indent='  ') + '''

    1) -j/--input_json INPUT_JSON
    2) -f/--input_json_file FILENAME
    3) --stdin

  JOB-BASED OBJECT REFERENCES

  ''' + fill('For now, job-based object references can only be used if provided as part of a full input JSON.', subsequent_indent='  ') + '\n'), prog='dx run', formatter_class=argparse.RawTextHelpFormatter)
parser_run.add_argument('path', help='Name or ID of program or app to run')
parser_run.add_argument('--alias', '--version', '--tag', dest='alias', help=fill('Tag or version of the app to run (default: \"default\" if an app)', width=56))
parser_run.add_argument('--folder', help=fill('The folder in which to output the results.  By default, the current working directory will be used.', width=56))
parser_run_input = parser_run.add_mutually_exclusive_group()
parser_run_input.add_argument('-i', '--input', help='''An input to be added using "<input name>=<input value>"
Examples:
  -ichunkSize=250000     # Numerical input
  -iname=\'\"hello world\"\' # Quotes required for strings
  -ireads=reads_name     # Names will be resolved''', action='append')
parser_run_input.add_argument('-j', '--input-json', help=fill('The full input JSON (keys=input field names, values=input field values)', width=56))
parser_run_input.add_argument('-f', '--input-json-file', dest='filename', help=fill('Load input JSON from the file'))
parser_run_input.add_argument('--stdin', help=fill('Interprets inputs from stdin instead of using the -i flags.  Format should be in the raw JSON with keys equal to the input names and values equal to their values.', width=56), action='store_true')
parser_run.set_defaults(func=run, verbose=False)
parser_map['run'] = parser_run

parser_kill = subparsers.add_parser('kill', help='Terminate a job that has not yet finished', prog='dx kill')
parser_kill.add_argument('jobid', help='ID of the job to terminate')
parser_kill.set_defaults(func=kill)
parser_map['kill'] = parser_kill

parser_find = subparsers.add_parser('find', help='Search functionality over data objects, projects, and jobs',
                                    description='Search functionality over data objects, projects, and jobs', prog='dx find')
subparsers_find = parser_find.add_subparsers()
parser_map['find'] = parser_find

parser_find_jobs = subparsers_find.add_parser('jobs', help='Finds jobs', description='Finds jobs with the given search parameters.  Output is formatted to show origin jobs on the left with its children jobs indented underneath it.  Output string includes the job ID, the time at which the job was created, and its current state.', parents=[global_args], prog='dx find jobs')
parser_find_jobs.add_argument('--user', help='User ID who launched the job')
parser_find_jobs.add_argument('--program', help='Program ID that job is running')
parser_find_jobs.add_argument('--project', help='Project context ID (output project)')
parser_find_jobs.add_argument('--state', help='State of the job, e.g. \"done\", \"failed\"')
parser_find_jobs.add_argument('--origin', help='Job ID of the top-level (user-initiated) job')
parser_find_jobs.add_argument('--parent', help='Job ID of the parent job, or the string \'none\' to indicate no parent')
parser_find_jobs.add_argument('--nodesc', help='Only return job IDs', action='store_false') # flag stored as true = use describe
parser_find_jobs.add_argument('--created-after', type=int, help='Timestamp after which the job was last created (negative number means ms in the past)')
parser_find_jobs.add_argument('--created-before', type=int, help='Timestamp before which the job was last created (negative number means ms in the past)')
parser_find_jobs.set_defaults(func=find_jobs)
parser_map['find jobs'] = parser_find_jobs

parser_find_data = subparsers_find.add_parser('data', help='Finds data objects', parents=[global_args], prog='dx find data')
parser_find_data.add_argument('--class', dest='classname', choices=['record', 'file', 'gtable', 'program', 'table'], help='Data object class')
parser_find_data.add_argument('--state', choices=['open', 'closing', 'closed', 'any'], help='State of the object')
parser_find_data.add_argument('--visibility', choices=['hidden', 'visible', 'either'], default='visible', help='Whether the object is hidden or not')
parser_find_data.add_argument('--name', help='Name of the object')
parser_find_data.add_argument('--properties', nargs='+', help='Key-value pairs of properties, e.g. \'--properties property_key property_value another_property_key another_property_value\'')
parser_find_data.add_argument('--type', help='Type of the data object')
parser_find_data.add_argument('--tag', help='Tag of the data object')
parser_find_data.add_argument('--link', help='Object ID that the data object links to')
parser_find_data.add_argument('--project', help='Project with which to restrict the results')
parser_find_data.add_argument('--folder', help='Folder path with which to restrict the results (\'--project\' must be used in this case)')
parser_find_data.add_argument('--recurse', help='Recurse into subfolders', action='store_true')
parser_find_data.add_argument('--mod-after', type=int, help='Timestamp after which the object was last modified (negative number means ms in the past)')
parser_find_data.add_argument('--mod-before', type=int, help='Timestamp before which the object was last modified (negative number means ms in the past)')
parser_find_data.add_argument('--created-after', type=int, help='Timestamp after which the object was created (negative number means ms in the past)')
parser_find_data.add_argument('--created-before', type=int, help='Timestamp before which the object was created (negative number means ms in the past)')
parser_find_data.add_argument('--describe', help='Also return descriptions of objects', action='store_true')
parser_find_data.set_defaults(func=find_data)
parser_map['find data'] = parser_find_data

parser_find_projects = subparsers_find.add_parser('projects', help='Finds projects', parents=[global_args], prog='dx find projects')
parser_find_projects.add_argument('--name', help='Name of the project')
parser_find_projects.add_argument('--level', choices=['LIST', 'VIEW', 'CONTRIBUTE', 'ADMINISTER'], help='Minimum level of permissions expected')
parser_find_projects.set_defaults(func=find_projects)
parser_map['find projects'] = parser_find_projects

parser_find_apps = subparsers_find.add_parser('apps', help='Finds apps', parents=[global_args], prog='dx find apps')
parser_find_apps.add_argument('--name', help='Name of the app')
parser_find_apps.add_argument('--category', help='Category of the app')
parser_find_apps.add_argument('-a', '--all', help='Whether to return all versions of the app', action='store_true')
parser_find_apps.add_argument('--unpublished', help='Whether to return unpublished apps as well', action='store_true')
parser_find_apps.add_argument('--owner', help='Owner of the app')
parser_find_apps.add_argument('--creator', help='Creator of the app version')
parser_find_apps.add_argument('--developer', help='Developer of the app')
parser_find_apps.add_argument('--created-after', type=int, help='Timestamp after which the app version was created (negative number means ms in the past)')
parser_find_apps.add_argument('--created-before', type=int, help='Timestamp before which the app version was created (negative number means ms in the past)')
parser_find_apps.add_argument('--mod-after', type=int, help='Timestamp after which the app was last modified (negative number means ms in the past)')
parser_find_apps.add_argument('--mod-before', type=int, help='Timestamp before which the app was last modified (negative number means ms in the past)')
parser_find_apps.set_defaults(func=find_apps)
parser_map['find apps'] = parser_find_apps

parser_dataobject_args = argparse.ArgumentParser(add_help=False)
parser_dataobject_args.add_argument('--visibility', choices=['hidden', 'visible'], default='visible', help='Whether the object is hidden or not')
parser_dataobject_args.add_argument('--name', help='Name of the object')
parser_dataobject_args.add_argument('--properties', nargs='+', help='Key-value pairs of properties, e.g. \'--properties property_key property_value another_property_key another_property_value\'')
parser_dataobject_args.add_argument('--types', nargs='+', help='Types of the data object')
parser_dataobject_args.add_argument('--tags', nargs='+', help='Tags of the data object')
parser_dataobject_args.add_argument('--project', help='Project (if not using the default project)')
parser_dataobject_args.add_argument('--details', help='JSON to store as details')
parser_dataobject_args.add_argument('--parents', help='Create folder (and its parents) if necessary', action='store_true')
parser_dataobject_args.add_argument('--folder', help='Folder path with which to restrict the results (\'--project\' must be used in this case)')

parser_upload = subparsers.add_parser('upload', help='Upload a file', parents=[parser_dataobject_args], prog="dx upload")
parser_upload.add_argument('filename', help='local filename to upload')
parser_upload.add_argument('--id-only', help='Print ID of the file object instead of the full description', action='store_true')
parser_upload.add_argument('--wait', help='Wait until the file has finished closing', action='store_true')
parser_upload.set_defaults(func=upload)
parser_map['upload'] = parser_upload

parser_new = subparsers.add_parser('new', help='Create a new data object', prog="dx new")
subparsers_new = parser_new.add_subparsers()
parser_map['new'] = parser_new

parser_new_project = subparsers_new.add_parser('project', help='Create a new project',
                                               prog='dx new project')
parser_new_project.add_argument('name', help='Name of the new project')
parser_new_project.set_defaults(func=new_project)
parser_map['new project'] = parser_new_project

parser_new_record = subparsers_new.add_parser('record', help='Create a new record',
                                              parents=[parser_dataobject_args],
                                              prog='dx new record')
parser_new_record.add_argument('--init', help='Record ID from which to initialize all metadata')
parser_new_record.set_defaults(func=new_record)
parser_map['new record'] = parser_new_record

parser_new_gtable = subparsers_new.add_parser('gtable', help='Create a new gtable', parents=[parser_dataobject_args], prog='dx new gtable')
parser_new_gtable.add_argument('--columns', help='JSON for specifying the columns')
parser_new_gtable.add_argument('--indices', help='JSON for specifying the indices')
parser_new_gtable.add_argument('--input', help='a filename containing the JSON input to be used (currently only used for overriding --columns and --indices)')
parser_new_gtable.set_defaults(func=new_gtable)
parser_map['new gtable'] = parser_new_gtable

parser_get_details = subparsers.add_parser('get_details', help='Get details of an object', prog="dx set_details")
parser_get_details.add_argument('path', help='Data object to get details for')
parser_get_details.set_defaults(func=get_details)
parser_map['get_details'] = parser_get_details

parser_set_details = subparsers.add_parser('set_details', help='Set details on an object', prog="dx set_details")
parser_set_details.add_argument('path', help='Data object to modify')
parser_set_details.add_argument('details', help='JSON to store as details')
parser_set_details.set_defaults(func=set_details)
parser_map['set_details'] = parser_set_details

parser_set_visibility = subparsers.add_parser('set_visibility', help='Set visibility on an object', prog='dx set_visibility')
parser_set_visibility.add_argument('path', help='Data object to modify')
parser_set_visibility.add_argument('visibility', choices=['hidden', 'visible'], help='Visibility that the object should have')
parser_set_visibility.set_defaults(func=set_visibility)
parser_map['set_visibility'] = parser_set_visibility

parser_add_types = subparsers.add_parser('add_types', help='Add types to an object', prog='dx add_types')
parser_add_types.add_argument('path', help='Data object to modify')
parser_add_types.add_argument('types', nargs='+', help='Types to add')
parser_add_types.set_defaults(func=add_types)
parser_map['add_types'] = parser_add_types

parser_remove_types = subparsers.add_parser('remove_types', help='Remove types from an object', prog='dx remove_types')
parser_remove_types.add_argument('path', help='Data object to modify')
parser_remove_types.add_argument('types', nargs='+', help='Types to remove')
parser_remove_types.set_defaults(func=remove_types)
parser_map['remove_types'] = parser_remove_types

parser_add_tags = subparsers.add_parser('add_tags', help='Add tags to an object', prog='dx add_tags')
parser_add_tags.add_argument('path', help='Data object to modify')
parser_add_tags.add_argument('tags', nargs='+', help='Tags to add')
parser_add_tags.set_defaults(func=add_tags)
parser_map['add_tags'] = parser_add_tags

parser_remove_tags = subparsers.add_parser('remove_tags', help='Remove tags from an object', prog='dx remove_tags')
parser_remove_tags.add_argument('path', help='Data object to modify')
parser_remove_tags.add_argument('tags', nargs='+', help='Tags to remove')
parser_remove_tags.set_defaults(func=remove_tags)
parser_map['remove_tags'] = parser_remove_tags

parser_rename = subparsers.add_parser('rename',
                                      help='Rename a project, folder, or object',
                                      description='Rename a project, folder, or object.  To indicate a project, append a colon character ":" after the project ID or name',
                                      prog='dx rename')
parser_rename.add_argument('path', help='Path to project, folder, or object to rename')
parser_rename.add_argument('name', help='New name')
parser_rename.set_defaults(func=rename)
parser_map['rename'] = parser_rename

parser_set_properties = subparsers.add_parser('set_properties', help='Set properties of an object', prog='dx set_properties')
parser_set_properties.add_argument('path', help='Data object to modify')
parser_set_properties.add_argument('properties', nargs='+', help='Key-value pairs of properties, e.g. \'--properties property_key property_value another_property_key another_property_value\'')
parser_set_properties.set_defaults(func=set_properties)
parser_map['set_properties'] = parser_set_properties

parser_unset_properties = subparsers.add_parser('unset_properties', help='Unset properties of an object', prog='dx unset_properties')
parser_unset_properties.add_argument('path', help='Data object to modify')
parser_unset_properties.add_argument('properties', nargs='+', help='Property names to unset')
parser_unset_properties.set_defaults(func=unset_properties)
parser_map['unset_properties'] = parser_unset_properties

parser_api = subparsers.add_parser('api', help='Make an API call', prog='dx api')
parser_api.add_argument('resource', help='is one of \"system\", a class name (e.g. \"record\"), or an entity ID such as \"record-xxxx\"')
parser_api.add_argument('method', help='a valid method for the resource as documented by the API document')
parser_api.add_argument('input_json', nargs='?', default="{}", help='the JSON input for the method as documented by the API document (if not given, \"{}\" is used)')
parser_api.add_argument('--input', help='a filename containing the JSON input to be used (takes precedence over the \'json\' argument)')
parser_api.add_argument('--stdin', help='Indicate that JSON input will be provided with a prompt', action='store_true')
parser_api.set_defaults(func=api)
parser_map['api'] = parser_api

# "Execution" starts here

# Take in things from the pipe, respecting quoted substrings
if not sys.stdin.isatty():
    for line in sys.stdin.read().splitlines():
        if len(line) > 0:
            args = parser.parse_args(args_list + shlex.split(line))
            args.func(args)
    
else:
    if len(args_list) > 0:
        args = parser.parse_args(args_list)
        args.func(args)
    else:
        parser.print_help()
        sys.exit(1)
