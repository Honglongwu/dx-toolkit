#!/usr/bin/env python
# DX_APP_WIZARD_NAME DX_APP_WIZARD_VERSION
# Generated by dx-app-wizard.
#
# Parallelized execution pattern (file input): Your app will subdivide
# a large chunk of work (in the form of an existing file object) into
# multiple pieces that can be processed in parallel and independently
# of each other, followed by a final "postprocess" stage that will
# perform any additional computations as necessary.
#
# See http://wiki.dnanexus.com/Building-Your-First-DNAnexus-App for
# instructions on how to modify this file.
#
# DNAnexus Python Bindings (dxpy) documentation:
#   http://autodoc.dnanexus.com/bindings/python/current/

# TODO: update to parallelize over a file (no gtable output)

import os
import dxpy

@dxpy.entry_point('postprocess')
def postprocess(process_outputs):
    for output in process_outputs:
        pass

    return {}

@dxpy.entry_point('process')
def process(file_id):
    output_hash = { "output": None }

    # Option #1
    # You can either run an executable to process the file
    dxpy.download_dxfile(file_id, 'input_file')
    subprocess.call(['some-executable', 'input_file'])
    output_file = dxpy.upload_local_file('subprocess_output_filename')
    output_hash["output"] = dxpy.dxlink(output_file)

    # Option #2
    # Or you can use the dxpy file handler and iterate over it
    # directly (the bindings will periodically download chunks of the
    # file at a time).
    my_file = dxpy.DXFile(file_id)
    for line in my_file:
        # Fill in code here to perform whatever computation is
        # necessary to process the line in the file.
        pass

    # If your subproblem has output, you can return it here:
    return output_hash

@dxpy.entry_point('main')
def main(DX_APP_WIZARD_INPUT_SIGNATURE):
DX_APP_WIZARD_INITIALIZE_INPUTDX_APP_WIZARD_DOWNLOAD_ANY_FILES
    # Split your input to be solved by the next stage of your app.
    # The following line takes advantage of the dx-unpack tool, which
    # will extract the file if compressed and leave it alone
    # otherwise.  splitting the resulting file for every 10000 lines
    # for each subjob running the "process" entry point.

    subprocess.call(['dx-unpack', '"DX_APP_WIZARD_PARALLELIZED_INPUT"'])
    # TODO: when dx-unpack outputs the new file name, we can use it in
    # place of "unpackedfile" below.

    subjobs = []
    with open('unpackedfile', 'r') as input_file:
        num_lines = 0
        subjob_file = None
        for line in input_file:
            if num_lines == 0:
                subjob_file = dxpy.new_dxfile()
            subjob_file.write(line)
            
        subjob_input = { "file_id": subjob_file.get_id() }
        subjobs.append(dxpy.new_dxjob(subjob_input, 'process'))

    # The following line creates the job that will perform the
    # "postprocess" step of your app.  We've given it an input field
    # that is a list of job-based object references created from the
    # "process" jobs we just created.  Assuming those jobs have an
    # output field called "output", these values will be passed to the
    # "postprocess" job.  Because these values are not ready until the
    # "process" jobs finish, the "postprocess" job WILL NOT RUN until
    # all job-based object references have been resolved (i.e. the
    # jobs they reference have finished running).
    #
    # If you do not plan to have the "process" jobs create output that
    # the "postprocess" job will require, then you can explicitly list
    # the dependencies to wait for those jobs to finish by setting the
    # "depends_on" field to the list of subjobs to wait for (it
    # accepts either dxpy handlers or string IDs in the list).  We've
    # included this parameter in the line below as well for
    # completeness, though it is unnecessary if you are providing
    # job-based object references in the input that refer to the same
    # set of jobs.

    postprocess_job = dxpy.new_dxjob(fn_input={"process_outputs": [subjob.get_output_ref("output") for subjob in subjobs]},
                                     fn_name='postprocess',
                                     depends_on=subjobs)

    # If you would like to include any of the output fields from the
    # postprocess_job as the output of your app, you should return it
    # here using a job-based object reference.  If the output field is
    # called "answer", you can pass that on here as follows:
    #
    # return {"app_output_field": postprocess_job.get_output_ref("answer"), ...}
    #
    # Tip: you can include in your output at this point any open
    # objects (such as gtables) which are closed by a job that
    # finishes later.  The system will check to make sure that the
    # output object is closed and will attempt to clone it out as
    # output into the parent container only after all subjobs have
    # finished.

    output = {}
DX_APP_WIZARD_OUTPUT
    return output

dxpy.run()
