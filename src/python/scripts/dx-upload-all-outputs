#!/usr/bin/env python
#
# Copyright (C) 2013-2014 DNAnexus, Inc.
#
# This file is part of dx-toolkit (DNAnexus platform client libraries).
#
#   Licensed under the Apache License, Version 2.0 (the "License"); you may not
#   use this file except in compliance with the License. You may obtain a copy
#   of the License at
#
#       http://www.apache.org/licenses/LICENSE-2.0
#
#   Unless required by applicable law or agreed to in writing, software
#   distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
#   WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
#   License for the specific language governing permissions and limitations
#   under the License.

import os, sys, json, argparse, subprocess
import pprint
import dxpy

''' This helper script uploads all output files from the virtual machine
running in the cloud to the cloud filesystem (S3).

Assumption
  * we are uploading a flat directory structure

Design
  
TODO

Issues
  * testing
  * recursive directory upload, or flat support only? 


Specification

Part 1: 
   Upload everything that is in the output directory, and generate a
   $HOME/job_output.json file that describes it. 
Part 2:
   If there is an output spec, compare against it. 

   I can get the input spec by doing a "describe" on the job, and extracting information from there. 
'''


## upload one file
fasta_gz = dxpy.upload_local_file("%s.fa.gz" % name);
