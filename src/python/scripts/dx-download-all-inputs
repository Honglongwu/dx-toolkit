#!/usr/bin/env python
#
# Copyright (C) 2013-2014 DNAnexus, Inc.
#
# This file is part of dx-toolkit (DNAnexus platform client libraries).
#
#   Licensed under the Apache License, Version 2.0 (the "License"); you may not
#   use this file except in compliance with the License. You may obtain a copy
#   of the License at
#
#       http://www.apache.org/licenses/LICENSE-2.0
#
#   Unless required by applicable law or agreed to in writing, software
#   distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
#   WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
#   License for the specific language governing permissions and limitations
#   under the License.

import os, sys, json, argparse, subprocess
import pprint
import dxpy

## Global convenience variables
pp = pprint.PrettyPrinter(indent=4)

'''
This will not be compatible with previous uses

TODO
  +* setup working test app
  +* make sure /in exists
  +* handle file arrays   
  +* hack to make it work for running the app locally
  
Questions
* testing, how to integrate into testing framework
* additional scripts
    + download-all-inputs
    upload-all-outputs
    download-input  [input_name]
    upload-input  [output_name]

* How should we report errors? 
   = example from [dx-log-stream]
     try 
       ...
     except Exception as e:
        print >> sys.stderr, "dx_log_stream: Error while initializing logging:", str(e)
        sys.exit(1)

   = example from dx-jobutil-report-error
     error_hash = {
      "error": {
          "type": args.type,
          "message": args.message
        }
      }

    with open(os.path.expanduser(os.path.join('~', 'job_error.json')), 'w') as error_file:
         error_file.write(json.dumps(error_hash, indent=4) + '\n')

'''

'''
Downloads all input files into the virtual machine

   job_input.json is in the working directory of the code.
   parse job_input.json, figure out the set of input files
   construct directory structure
   download the files (in parallel, or sequentially)
'''

'''
A simple example of the input specification:

{
    "seq2": {
        "$dnanexus_link": {
            "project": "project-BKJfY1j0b06Z4y8PX8bQ094f", 
            "id": "file-BKQGkjj0b06xG5560GGQ001K"
        }
    }, 
    "seq1": {
        "$dnanexus_link": {
            "project": "project-BKJfY1j0b06Z4y8PX8bQ094f", 
            "id": "file-BKQGkgQ0b06xG5560GGQ001B"
        }
    }
    "blast_args": "", 
    "evalue": 0.01
}

The first two elements are files {seq1, seq2}, the other elements {blast_args, evalue}.
The file for seq2 should be saved into: <idir>/seq2/filename

source command line
  -iseq1=NC_000868.fasta -iseq2=NC_001422.fasta 

file seq1 is supposed to appear in the virutal machine at path:
<idir>/seq1/NC_000868.fasta


File Arrays

{
    "reads": [{
        "$dnanexus_link": {
            "project": "project-BKJfY1j0b06Z4y8PX8bQ094f", 
            "id": "file-BKQGkjj0b06xG5560GGQ001K"
        }
    }, 
    {
        "$dnanexus_link": {
            "project": "project-BKJfY1j0b06Z4y8PX8bQ094f", 
            "id": "file-BKQGkgQ0b06xG5560GGQ001B"
        }
    }]
}

This file array with two files, will appear in the virtual machine as:
<idir>/reads/<handler.name>
<idir>/reads/<handler.name>
'''

'''
  extract list of files, returns a set of directories to create, and 
  a set of files, with sources and destinations. 
'''
def parse_job_input(idir, job_input_file):
    with open(job_input_file) as fh:
        job_input = json.load(fh)
        pp.pprint(job_input)

        files = list() 
        dirs = set()  ## directories to create under <idir>
        
        ## local function for adding a file to the list of files to be created
        ## for example: 
        ##   "seq1" <$dnanexus_link ... >    ---> <idir>/seq1/<filename>
        def add_file(iname, value):
            handler = dxpy.get_handler(value)
            if not isinstance(handler, dxpy.DXFile):
                return
            filename = handler.name
            kv = {'trg_fname' : os.path.join(idir, iname, filename),
                  'src_fname' : handler.id}
            files.append(kv)
            dirs.add(iname)

        for input_name, value in job_input.iteritems():
            if dxpy.is_dxlink(value):
                ## This is a single file
                add_file(input_name, value)
            elif isinstance(value, list):
               ## This is a file array, we use the field name as the directory
               for link in value:
                   add_file(input_name, link)

        return (dirs, files)
    
'''
key --- target file name
value --- file descriptor

example:
key == "seq1"
desc == { "$dnanexus_link": {
            "project": "project-BKJfY1j0b06Z4y8PX8bQ094f", 
            "id": "file-BKQGkgQ0b06xG5560GGQ001B"
        }
'''
def download_all(inputs):
    for rec in inputs:
        print("download file: " + rec['src_fname'] + "-> " + rec['trg_fname'])
        dxpy.download_dxfile(rec['src_fname'], rec['trg_fname'])

'''
 create a directory if it does not already exist .

 TODO: report appropriate errors if this is a file, instead of a directory
'''
def ensure_dir(d):
    pp.pprint("ensure_dir " + d)
    if not os.path.exists(d):
        print ("create_dir " + d)
        os.mkdir(d)

'''
create a set of directories, so we could store the input files.
For example, seq1 could be stored under:
   /out/seq1/NC_001122.fasta

TODO: this call could fail, we need to report a reasonable error code
'''
def create_dirs(idir, dirs):
    print ("create_dirs " + str(len(dirs)))
    if len(dirs) == 0:
        return
    ## create each subdir
    for d in dirs:
        ensure_dir(os.path.join(idir, d))

'''
When we run a script locally, we don't have access to the "/in" directory (<idir>). To get around this problem, we convert "/in" to "./in", if we can't write into "/in".

Note: this is a hack, we need to find a better way to do this.
'''
def setup_idir_local_exec_hack(idir):
    ## create the <idir> directory
    if not os.access("/", os.W_OK):
        idir = "." + idir
    ensure_dir(idir)
    return idir

## entry point
idir = '/in'    ## input directory, where all inputs are downloaded
idir = setup_idir_local_exec_hack(idir)

job_input_file = "./job_input.json"
dirs, inputs = parse_job_input(idir, job_input_file)
pp.pprint(inputs)
pp.pprint(dirs)

## Create the directory structure, in preparation for download.
## Allows performing the download in parallel.
create_dirs(idir, dirs)

## Download the files, currently, this is done sequentially (one file at 
## a time.
download_all(inputs)


